<!DOCTYPE html>
<html>
	<head>
		<meta name="author" content="reiver" />

		<title>Predicting Gender On Twitter</title>

		<meta name="keywords" content="twitter, gender, sex" />

		<meta name="DC.Date.Created" content="2013-03-02T16:02:57-08:00" />
	</head>
	<body>
			<p>
				Can you use <em>machine learning</em> and <em>statistics</em> to predict the gender of someone on Twitter?
			</p>

			<section>
				<h2>Male or Female?</h2>
				<p>
					If you have spent any kind of time online, then you have probably heard of the various (online) <em>social networks</em> out there.
					Things such as <em>Facebook</em>, <em>Orkut</em>, <em>VK</em> (popular in Russia), <em>Mixi</em> (popular in Japan) and <em>Twitter</em>.
				</p>
				<p>
					Many of these social network require you to tell them whether you are a <em>male</em> or <em>female</em>.
					(To some, this information is invaluable.)
				</p>
				<p>
					However, Twitter doesn't
				</p>
			</section>

			<section>
				<h2>Twitter</h2>
				<p>
					<img src="bird_blue_48.png" style="float:right;" />
					Twitter in particular, is an interesting social network.
					Both from the point of view of someone using it.
					And from the point of view of someone doing research.
				</p>
				<p>
					<a href="http://twitter.com">Twitter</a> has made it easy for people to sign up.
					Some websites want to know all your (deepest darkest) details before they let you sign up.
					Twitter doesn't.
					All a person has to provide to Twitter to sign up is a <em>name</em> and <em>e-mail address</em>.
					That's it.
				</p>
				<figure>
					<img src="twitter-signup.png" />
					<figcaption>
						<strong>Figure 1.</strong>
						Twitter's signup form
					</figcaption>
				</figure>
				<p>
					(You don't have to tell Twitter <em>where you live</em> or your <em>date of birth</em> or <em>gender</em>, etc.)
				</p>
				<p>
					And really, the <em>name</em> doesn't even have to be real.
					Using a pseudonym or any other name you want to use is just fine.
					If you want your name on Twitter to be "Panda Puncher", go right ahead.
				</p>
				<p>
					(This is one of the strengths and attractions of Twitter in my opinion.)
				</p>
			</section>


			<section>
				<h2>Inferring Gender</h2>

				<p>
					Even though Twitter doesn't ask for your <em>gender</em>, doesn't mean no one cares about it.
				</p>
				<p>
					(People involving in <em>advertising</em> care about it a lot. People involved with <em>identity</em>. People involved in fraud detection care too.)
				</p>
				<p>
					But if someone doesn't self-assert their <em>gender</em> (to say they are <em>male</em> or <em>female</em>), <strong>can we infer someone's gender from their Twitter account?</strong>
				</p>
				<p>
					I'd say the answer is "yes".
					(Probably because I've already worked on commercial projects that did <em>gender prediction</em> with similar types of data :-) )
				</p>
				<p>
					I think you can infer someone's gender without them <em>telling you</em> what it is, based on <em>clues</em> they leave around, with varying degrees of success.
				</p>
				<p><strong>
					Consider, for example, a population that is 50% male and 50% female.
					If you guessed "<em>male</em>" every single time, then (with a random sample) your <em>gender prediction</em> would be accurate 50% of the time.
					This is kind of like the idiom: <em>a stopped clock is right twice a day</em>.
				</strong></p>
				<p>
					Any <em>gender prediction</em> engine we consider "good" should do better than this.
					And I can even think of different ways that may work.
				</p>

				<section>
					<h3>Examples</h3>

					<p>
						For example, consider the profile of a friend of mine of Twitter, in <strong>figure 2</strong>.
					</p>
					<figure>
						<img src="harpersnotes-clues.png" />
						<figcaption>
							<strong>Figure 2.</strong>
							Twitter profile of <a href="http://twitter.com/harpersnotes">@harpersnotes</a> with 3 clues useful for <em>gender predication</em> marked in red.
						</figcaption>
					</figure>
					<p>
						(Remember, these <em>clues</em> are for a <em>machine learning</em> system to use.
						Of course a human can do this categorization pretty easily, but we want to automate it.)
					</p>
					<p>
						The first clue is the <em>avatar image</em>.
						A <em>photo</em> was used.
						We could use <em>computer vision</em> to infer the gender of that image.
					</p>
					<p>
						The second clue is the <em>given name</em> ("Richard").
						Many <em>given names</em> are highly gender skewed.
						(I suspect there probably <strong>a lot</strong> more males with the name "Richard" than there are females.
						Which would probably make it a "good" <em>gender predictor</em>.)
					</p>
					<p>
						The third clue probably seems less obvious, but the Twitter profile <em>description</em> can also give a clue to the gender.
						It could be that males and females use language differently, and that the language used in the <em>description</em> is a <em>gender predictor</em>.
					</p>
					<p>
						There is actually a fourth clue not marked in the <strong>figure 2</strong>.
						The Twitter screen name ("@harpersnotes").
						Like the third clue, it could be that males and females use language differently for the Twitter screen name too.
						And thus the words used the Twitter screen name could be a <em>gender predictor</em>.
					</p>
					<p>
						As a possible fifth clue also not shown in <strong>figure 2</strong>, it is conceivable that the location could be a <em>gender predictor</em>.
						Perhaps not the location in <strong>figure 2</strong> ("Albuquerque, New Mexico, USA "),
						but say if the location is somewhere where there is a strong gender skew, such as India or China, or even a remote mining town in Northern Canada where the only people living there are mining workers, and all the miners are males.
					</p>
					<p>
						(And Twitter does offer us other <em>clues</em> not shown in <strong>figure 2</strong>.
						Perhaps the Twitter user ID gives us a <em>clue</em>.
						For example, if more males signed up for Twitter in the first 3 years that Twitter existed, and we know that Twitter user IDs with a range between certain numbers are from that era,
						then we can predict <em>male</em> for all users with Twitter user IDs we think are from that era, and predict nothing outside of that.)
					</p>
					<p>
						Now obviously, in general, some of these <em>clues</em> are going to be better <em>gender predictors</em> than others.
						(Perhaps the <em>given name</em> is a better <em>gender predictor</em> than the <em>avatar image</em> because many people don't use photos for their <em>avatar image</em>.)
					</p>
					<p>
						And for specific profiles, which is <em>gender predictor</em> is accurate will vary; but we expect trends.
					</p>
					<p>
						Here's an example of another friend whose profile really gives us no clues, or barely any, as seen in <strong>figure 3</strong>:
					</p>
					<figure>
						<img src="rnadomtc-clues.png" />
						<figcaption>
							<strong>Figure 3.</strong>
							Twitter profile of <a href="http://twitter.com/rNadomtC">@rNadomtC</a>.
						</figcaption>
					</figure>
					<p>
						Probably not much in the way of clues here, in <strong>figure 3</strong>.
						Not unless <em>not giving clues</em> is gender skewed :-)
					</p>
					<p>
						(Note that I'm not trying to list out every possible data source that may be useful for <em>gender prediction</em>.
						I am only trying to give you a "flavor" of the strategies that could be used.
						Is there a gender skew with the apps people use and which send tweets to twitter?
						Is there a gender skew in the <em>time of day</em> people tweet, or retweet, etc?
						Does a person's social network (in the <em>graph theory</em> sense of the term) give clue's to their gender?
						There are many possibilities one can test and build <em>machine learning</em> systems around.)
					</p>
				</section>

				<section>
					<h3>Accuracy</h3>
					<p>
						Now, this doesn't mean a single <em>gender prediction</em> strategy will always be 100% accurate.
						(There is very likely going to be some level of error.)
						But these strategies will have some level of accuracy.
						And even with an error, these <em>gender predictions</em> may still be useful.
					</p>
					<p>
						<strong>You could even (somehow) combine these different <em>gender prediction</em> strategies together, to create a single <em>more accurate</em> strategy for <em>gender prediction</em> with a lower error rate.</strong>
					</p>
				</section>

				<section>
					<h3>Analysis</h3>
					<p>
						Developing a <em>gender prediction</em> "engine" really could be done by just taking a reference data set of known male and female accounts and doing some analysis work.
						(I.e., get a set of Twitter accounts that you know the gender for, and use some statistics, machine learning and educated guesses to discover differences between various <em>things</em> that are more common with males than female, and what <em>things</em> are more common with females than males. And use that to come up with a model you can use for making <em>gender predictions</em>.)
						And then validate the resulting model against another (separate) set of Twitter accounts for which you know the gender.
						(Just to verify that your model is a "good" one.)
					</p>
					<p>
						Of course, these "engines" can have all sorts of nuances, special conditions, and may need to be updated from time to time, as past analysis work done may no longer be applicable.
					</p>
				</section>

				<section>
					<h3>Tweets</h3>
					<p>
						Another <em>clue</em> I haven't yet mention (because I wanted to save it for last) are a person's tweets.
						Specifically, the text found in a person's tweet.
					</p>
					<p>
						Are there differences between the way males and females tweet?
						I suspect so (at least some of the time, if not a lot of the time).
					</p>
					<p>
						And in fact, a team of 3 (<a href="http://www.cs.cmu.edu/~dbamman/">David Bamman</a>, <a href="http://www.cc.gatech.edu/~jeisenst/">Jacob Eisenstein</a> and <a href="http://www.stanford.edu/~tylers/">Tyler Schnoebelen</a>) did <a href="http://arxiv.org/abs/1210.4567">some research and analysis work</a> to find some differences.
					</p>
				</section>
			</section>


			<section>
				<h2>Gender in Twitter: Styles, stances, and social networks</h2>
				<p>
					<a href="http://www.cs.cmu.edu/~dbamman/">David Bamman</a>, <a href="http://www.cc.gatech.edu/~jeisenst/">Jacob Eisenstein</a> and <a href="http://www.stanford.edu/~tylers/">Tyler Schnoebelen</a>
					published the results of their work (open access) <a href="http://arxiv.org/abs/1210.4567">on arXiv</a>.
					(I encourage you to read it yourself, after reading this article.)
					There is also a <a href="http://stanford.edu/%7Etylers/notes/presentations/Twitter_Gender_presentation_10-25-12.pptx">related (powerpoint) presentation</a> available.
					And for those who want to do a little <em>digging</em> of their own, into their results, they have also made their <a href="http://www.cs.cmu.edu/~dbamman/twitter14K.html">data set</a> avilable.
				</p>
				<p>
					Here is the abstract from their paper:
				</p>
				<blockquote cite="http://arxiv.org/abs/1210.4567">
					<p>
						We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 users of Twitter. Prior quantitative work on gender often treats this social variable as a binary; we argue for a more nuanced approach. By clustering Twitter feeds, we find a range of styles and interests that reflects the multifaceted interaction between gender and language. Some styles mirror the aggregated language-gender statistics, while others contradict them. Next, we investigate individuals whose language better matches the other gender. We find that such individuals have social networks that include significantly more individuals from the other gender, and that in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms. 
					</p>
				</blockquote>
				<p>
					(<a href="http://arxiv.org/abs/1210.4567">Link</a>)
				</p>
				<p>
					So let's looks at the paper.
				</p>
				<p>
					They mentioned some prior related work by others:
				</p>
				<blockquote cite="http://arxiv.org/abs/1210.4567">
					<p>
						<abbr title="Herring, Susan C. &amp; Paolillo, John. (2006). Gender and genre variation in weblogs. Journal of Sociolinguistics 10(4):439–459.">Herring and Paolillo 2006</abbr> attempted to apply the informational/involvement word class features identified by <abbr title="Argamon, Shlomo, Koppel, Moshe, Fine, Jonathan &amp; Shimoni, Anat Rachel. (2003). Gender, genre, and writing style in formal written texts. Text 23(3): 321-346.">Argamon et al. 2003</abbr> to a corpus of blog data.
						After controlling for the genre of the blog, they found no significant gender differences in the frequency of the word classes, though they did find gender differences in the selection of genres: women wrote more "diary" blogs and men wrote more "filter" blogs that link to content from elsewhere in the web.
						Moreover, the genres themselves did show a significant association with the gender - based features: the "diary" genre included more features thought to be predictive of women, and vice versa.
						But within each genre, male and female language use was not distinguishable according to the informational/involvement feature set proposed by <abbr title="Argamon, Shlomo, Koppel, Moshe, Fine, Jonathan &amp; Shimoni, Anat Rachel. (2003). Gender, genre, and writing style in formal written texts. Text 23(3): 321-346.">Argamon et al. 2003</abbr>.

					</p>
					<p>
						[...]
					</p>
					<p>
						<abbr title="Argamon, Shlomo, Koppel, Moshe, Pennebaker, James & Schler, Jonathan. (2007). Mining the blogosphere: Age, gender, and the varieties of self-expression. First Monday 12(9).">Argamon, Koppel, Pennebaker, &amp; Schler 2007</abbr> assemble 19,320 English blogs (681,288 posts, 140 million words); they build a predictive model of gender from the 1,000 words with the highest information gain, obtaining accuracy of 80.5%.
						For post hoc analysis, they apply two word categorizations: parts-of-speech (finding that men use more determiners and prepositions, while women use more personal pronouns, auxiliary verbs, and conjunctions) and an automatic categorization based on factor analysis.
						Some of the factors are content - based (politics and religion), while others are more stylistic.
						In general, the content - based factors are used more often by men, and the stylistic factors are used more by women -- including a factor centered on swear words.
					</p>
				</blockquote>
				<p>
					Not directly Twitter related, but interesting.
				</p>
				<blockquote cite="http://arxiv.org/abs/1210.4567">
					<p>
						<abbr title="Rao, Delip, Yarowsky, David, Shreevats, Abhishek & Gupta, Manaswi. (2010). Classifying latent user attributes in Twitter. Proceedings of the 2nd international Workshop on Search and Mining User-Generated Contents. 37-44.">Rao et al. 2010</abbr> assembled a dataset of microblog posts by 1,000 people on the Twitter social media platform.
						They then built a predictive model that combined several million n-gram features with more traditional word and phrase classes.
						Their best model obtains an accuracy of 72.3%, slightly outperforming a model that used only the word class features.
						Post hoc analysis revealed that female authors were more likely to use emoticons, ellipses (...), expressive lengthening (<i>nooo waaay</i>), repeated exclamation marks, puzzled punctuation (combinations of <i>?</i> and <i>!</i>), the abbreviation <i>omg</i>, and transcriptions of backchannels like <i>ah</i>, <i>hmm</i>, <i>ugh</i>, and <i>grr</i>.
						The only words that they reported strongly attaching to males were affirmations like <i>yeah</i> and <i>yea</i>.
						However, a crucial side note to these results is that the author pool was obtained by finding individuals with social network connections to unambiguously gendered entities: sororities, fraternities, and hygiene products.
						Assumptions about gender were thus built directly into the data acquisition methodology, which is destined to focus on individuals with very specific types of gendered identities.
					</p>
					<p>
						<abbr title="Burger, John D., Henderson, John, Kim, George & Zarrella, Guido. (2011). Discriminating gender on Twitter. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. 1301-1309.">Burger, Henderson, Kim, &amp; Zarrella 2011</abbr> applied a different approach to build a corpus with gender metadata, by following links to Twitter from blogs in which gender was explicitly indicated in the profile (they also performed some manual quality assurance by reading the associated Twitter profiles).
						Analyzing more than 4 million tweets from 184,000 authors in many different languages (66.7% English), they obtained a predictive accuracy of 75.5% when using multiple tweets from each author, and 67.8% by using a single message per author.
						Remarkably, both of these were higher than the accuracy of human raters, who predicted gender at an accuracy of 65.7% from individual messages.
						The post hoc analysis yielded results that were broadly similar to those of <abbr title="Rao, Delip, Yarowsky, David, Shreevats, Abhishek & Gupta, Manaswi. (2010). Classifying latent user attributes in Twitter. Proceedings of the 2nd international Workshop on Search and Mining User-Generated Contents. 37-44.">Rao et al.</abbr>:
						emoticons and expressive words like <i>aha</i>, <i>ooo</i>, <i>haha</i>, <i>ay!</i> were correlated with female authors, and there were few words correlated with males.
						The character sequences <i>ht</i>, <i>http</i>, <i>htt</i>, <i>Googl</i>, and <i>Goog</i> were among the most prominent male-associated features.
					</p>
					<p>
						[...]
					</p>
					<p>
						From the accuracy of these predictive models, it is indisputable that there is a strong relationship between language and gender, and that this relationship is detectable at the level of individual words and n-grams.
					</p>
				</blockquote>
				<p>
					And for their work:
				</p>
				<blockquote cite="http://arxiv.org/abs/1210.4567">
					<p>
						By clustering the authors in our dataset, we identify a range of different styles and topical interests.
						Many of these clusters have strong gender orientations, but their use of linguistic resources sometimes directly conflicts with theaggregated language-gender statistics.
						We find that linguistic tendencies that have previously been attributed to women or men as undifferentiated social groups often describe only a subset of individuals; there are strongly gendered styles that use language resources in ways that are odds with the overall aggregated statistics. 
					</p>
				</blockquote>
				<p>
					Not surprising.
					Language usage is a predictor, but not prefect.
					There is error in the prediction.
				</p>
				<blockquote cite="http://arxiv.org/abs/1210.4567">
					<p>
						[W]e build a classifier capable of determining the gender of microblog authors from their writing style, with an accuracy of 88%.
						We focus on the individuals that the classifier gets wrong, and examine their language in the context of their online social networks.
						We find a significant correlation between the use of mainstream gendered language — as represented by classifier confidence — and social network gender homophily (how much a social network is made up of same - sex individuals).
						Individuals whose gender is classified incorrectly have social networks that are much less homophilous than those of the individuals that the classifier gets right.
						While the average social network in our corpus displays significant homophily (63% of connections are same - gender), social network features provide no marginal improvement in the classifier performance.
						That is, social network gender homophily and the use of mainstream gendered linguistic features are closely linked, even after controlling for author gender
					</p>
				</blockquote>
				<p>
					So, they build a <em>gender prediction</em> engine and then
					they ran a Twitter data set for which they already knew the gender for each account.
					Once they did that they noted the accounts which their <em>gender prediction</em> engine was wrong.
					<strong>They then looked closer at those accounts which the <em>gender prediction</em> engine was wrong.</strong>
				</p>
			</section>



			<section>
				<h1>Citation</h1>
				<p>
					<span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rft_id=info%3Aarxiv%2F1210.4567v1&rft.atitle=Gender+in+Twitter%3A+Styles%2C+stances%2C+and+social+networks&rft.date=2012&rfr_id=info%3Asid%2Fscienceseeker.org&rft.au=David+Bamman&rft.au=Jacob+Eisenstein&rft.au=Tyler+Schnoebelen&rfs_dat=ss.included=1&rfe_dat=bpr3.included=1;bpr3.tags=Computer+Science+%2F+Engineering">David Bamman, Jacob Eisenstein & Tyler Schnoebelen (2012). Gender in Twitter: Styles, stances, and social networks, <span style="font-style:italic;"> </span>   arXiv: <a rel="author" href="http://arxiv.org/abs/1210.4567v1">1210.4567v1</a></span>
				</p>
			</section>
	</body>
</html>

