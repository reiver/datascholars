<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8" />
		<title>DataScholars - Data Science, Computer Science, Machine Learning, Artificial Intelligence, Computational Social Science, Data Mining, Analytics, Visualization</title>
		<link rel="stylesheet" href="3/normalize/normalize.css" />
		<link rel="stylesheet" href="screen.css" />
		<link rel="alternate" href="/feed/blog.rss" title="DataScholars" type="application/rss+xml" />

		<script src="../../../../../3/jquery/jquery-1.9.1.min.js"></script>
	</head>

	<body>
		<header>
			<h1><a href="http://datascholars.com/">DataScholars</a></h1>
			<nav>
				<ul>
					<li>
						<a href="/about.html">About</a>
					</li>
					<li>
						<a href="/subscribe.html">Subscribe</a>
					</li>
					<li>
						<a href="/sphere.html">Sphere</a>
					</li>
				</ul>
			</nav>
			<p class="blurb">
				A blog about
				<em>data science</em>,
				<em>computer science</em>,
				<em>machine learning</em>,
				<em>artificial intelligence</em>,
				<em>computational social science</em>,
				<em>data mining</em>,
				<em>analysis</em>,
				and
				<em>visualization</em>.
			</p>
		</header>






		<article>
			<div class="pubdate">
				<time datetime="2013-06-05T06:44:48-07:00">June 5, 2013</time>
			</div>
			<h1><a href="post/2013/06/05/deep_learning_using_svm/">Deep Learning using Support Vector Machines (Yichuan Tang)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://arxiv.org/abs/1306.0239">
			<p>
				Recently, fully-connected and convolutional neural networks have been trained to reach state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics data.
				For classification tasks, much of these "deep learning" models employ the softmax activation functions to learn output labels in 1-of-K format.
				In this paper, we demonstrate a small but consistent advantage of replacing softmax layer with a linear support vector machine.
				Learning minimizes a margin-based loss instead of the cross-entropy loss.
				In almost all of the previous works, hidden representation of deep networks are first learned using supervised or unsupervised techniques, and then are fed into SVMs as inputs.
				In contrast to those models, we are proposing to train all layers of the deep networks by backpropagating gradients through the top level SVM, learning features of all layers.
				Our experiments show that simply replacing softmax with linear SVMs gives significant gains on datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.
			</p>
		</blockquote>
		<p>
			<a href="http://arxiv.org/abs/1306.0239">arXiv:1306.0239</a> [cs.LG]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-06-04T07:13:20-07:00">June 4, 2013</time>
			</div>
			<h1><a href="post/2013/06/04/bayesian_predicting_the_popularity_of_tweets/">A Bayesian Approach for Predicting the Popularity of Tweets (Tauhid Zaman, Emily B. Fox, Eric T. Bradlow)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://arxiv.org/abs/1304.6777">
			<p>
				We predict the popularity of short messages called tweets created in the micro-blogging site known as Twitter.
				We measure the popularity of a tweet by the time-series path of its retweets, which is when people forward the tweet to others.
				We develop a probabilistic model for the evolution of the retweets using a Bayesian approach, and form predictions using only observations on the retweet times and the local network or "graph" structure of the retweeters.
				We obtain good step ahead forecasts and predictions of the final total number of retweets even when only a small fraction (i.e. less than one tenth) of the retweet paths are observed.
				This translates to good predictions within a few minutes of a tweet being posted and has potential implications for understanding the spread of broader ideas, memes, or trends in social networks and also revenue models for both individuals who "sell tweets" and for those looking to monetize their reach.
			</p>
		</blockquote>
		<p>
			<a href="http://arxiv.org/abs/1304.6777">arXiv:1304.6777</a> [cs.SI]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-31T07:59:52-07:00">May 31, 2013</time>
			</div>
			<h1><a href="post/2013/05/31/john_langford_on_machine_learning/">John Langford on Machine Learning</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://hunch.net/~jl/">John Langford</a> is a machine learning research scientist at Microsoft Research New York
			and the principal developer of <a href="http://hunch.net/~vw/">Vowpal Wabbi</a>.
		</p>
		<p>
			Here <a href="http://www.youtube.com/watch?v=FBXZvpvktGU">John Langford talks</a> about machine learning.
		</p>

		<figure>
			<iframe width="420" height="315" src="http://www.youtube.com/embed/FBXZvpvktGU" frameborder="0" allowfullscreen="true"></iframe>
			<figcaption>
				<b>Figure 1.</b>
				Machine Learning for Industry with Microsoft Research Lead Scientist
			</figcaption>
		</figure>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-30T07:35:06-07:00">May 30, 2013</time>
			</div>
			<h1><a href="post/2013/05/30/vw/">Vowpal Wabbit (VW): Fast Open Source Optimization</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://hunch.net/~vw/">Vowpal Wabbit</a> (or just <a href="http://hunch.net/~vw/">VW</a> for short) is an open source system designed to be a fast, scalable, useful learning algorithm, used for solving optimization problems.
		</p>
		<p>
			<a href="http://github.com/JohnLangford/vowpal_wabbit/wiki/Examples">Examples</a> are available <a href="http://github.com/JohnLangford/vowpal_wabbit/wiki/Examples">here</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-29T21:42:19-07:00">May 29, 2013</time>
			</div>
			<h1><a href="post/2013/05/29/item-based_collaborative_filtering_recommendation_algorithms/">Item-based Collaborative Filtering Recommendation Algorithms (Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://wwwconference.org/www10/cdrom/papers/519/index.html">
			<p>
				Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction.
				These systems, especially the k-nearest neighbor collaborative filtering based ones, are achieving widespread success on the Web.
				The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems.
				These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity.
				In traditional collaborative filtering systems the amount of work increases with the number of participants in the system.
				New recommender system technologies are needed that can quickly produce high quality recommendations, even for very large-scale problems.
				To address these issues we have explored item-based collaborative filtering techniques.
				Item-based techniques first analyze the user-item matrix to identify relationships between different items, and then use these relationships to indirectly compute recommendations for users.
			</p>
			<p>
				In this paper we analyze different item-based recommendation generation algorithms.
				We look into different techniques for computing item-item similarities (e.g., item-item correlation vs. cosine similarities between item vectors) and different techniques for obtaining recommendations from them (e.g., weighted sum vs. regression model).
				Finally, we experimentally evaluate our results and compare them to the basic k-nearest neighbor approach.
				Our experiments suggest that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available user-based algorithms.
			</p>
		</blockquote>
		<p>
			[<a href="http://wwwconference.org/www10/cdrom/papers/519/index.html">HTML</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-14T07:12:50-07:00">May 14, 2013</time>
			</div>
			<h1><a href="post/2013/05/14/bayesian_sparse_distributed_memory/">Approximating Bayesian inference with a sparse distributed memory system (Joshua T. Abbott, Jessica B. Hamrick, Thomas L. Griffiths)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://cocosci.berkeley.edu/tom/papers/ApproxInferenceWithSDM.pdf">
			<p>
				Probabilistic models of cognition have enjoyed recent success in explaining how people make inductive inferences.
				Yet, the difficult computations over structured representations that are often required by these models seem incompatible with the continuous and distributed nature of human minds.
				To reconcile this issue, and to understand the implications of constraints on probabilistic models, we take the approach of formalizing the mechanisms by which cognitive and neural processes could approximate Bayesian inference.
				Specifically, we show that an associative memory system using sparse, distributed representations can be reinterpreted as an importance sampler, a Monte Carlo method of approximating Bayesian inference.
				This capacity is illustrated through two case studies: a simple letter reconstruction task, and the classic problem of property induction.
				Broadly, our work demonstrates that probabilistic models can be implemented in a practical, distributed manner, and helps bridge the gap between algorithmic- and computational-level models of cognition.
			</p>
		</blockquote>
		<p>
			[<a href="http://cocosci.berkeley.edu/tom/papers/ApproxInferenceWithSDM.pdf">PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-12T08:39:40-07:00">May 12, 2013</time>
			</div>
			<h1><a href="post/2013/05/12/convex_optimization/">Video Lectures: Convex Optimization, by Stephen Boyd</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Convex Optimization has become more and more important to people researching machine learning.
		</p>
		<p>
			Stephen Boyd has a series of video lectures available on this topic.
		</p>
		<p>
			The video lectures are in two parts: "Convex Optimization I" and "Convex Optimization II".
			Here is the description of the "Convex Optimization I" sub-series:
		</p>
		<blockquote>
			<p>
				Convex Optimization I concentrates on recognizing and solving convex optimization problems that arise in engineering.
				Convex sets, functions, and optimization problems.
				Basics of convex analysis.
				Least-squares, linear and quadratic programs, semidefinite programming, minimax, extremal volume, and other problems.
				Optimality conditions, duality theory, theorems of alternative, and applications.
				Interior-point methods.
				Applications to signal processing, control, digital and analog circuit design, computational geometry, statistics, and mechanical engineering.
			</p>
		</blockquote>
		<p>
			And here is the description for the "Convex Optimization II" sub-series:
		</p>
		<blockquote>
			<p>
				This course introduces topics such as subgradient, cutting-plane, and ellipsoid methods.
				Decentralized convex optimization via primal and dual decomposition.
				Alternating projections.
				Exploiting problem structure in implementation.
				Convex relaxations of hard problems, and global optimization via branch &amp; bound.
				Robust optimization.
				Selected applications in areas such as control, circuit design, signal processing, and communications.
			</p>
		</blockquote>
		<p>
			All video below:
		</p>
		<ul>
			<li>
				<a href="http://www.youtube.com/watch?v=McLq1hEq3UY">Lecture 1: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=P3W_wFZ2kUo">Lecture 2: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=kcOodzDGV4c">Lecture 3: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=lEN2xvTTr0E">Lecture 4: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=Ry5i8DGZrJs">Lecture 5: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=-T9cloGG_80">Lecture 6: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=VxQ8VHm1Ci4">Lecture 7: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=FJVmflArCXc">Lecture 8: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=3Q9mMluX3Gw">Lecture 9: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=gH13lxieYFU">Lecture 10: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=GxK04B9SVg4">Lecture 11: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=mNzu42FrlHo">Lecture 12: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=FkPLteYMK40">Lecture 13: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=ZmvQ7GQ_gPg">Lecture 14: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=sTCtkkqrY8A">Lecture 15: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=Ap8LGbCVx4I">Lecture 16: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=StlHUwd_AgM">Lecture 17: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=oMRVDILkpUI">Lecture 18: Convex Optimization I</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=HZW-9Ar0iVc">Lecture 19: Convex Optimization I</a>
			</li>
		</ul>
		<ul>
			<li>
				<a href="http://www.youtube.com/watch?v=U3lJAObbMFI">Lecture 1: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=ZniZaKCTktI">Lecture 2: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=B51GgGCHBRk">Lecture 3: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=kE3wtUaQzpA">Lecture 4: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=fhAFzmnFVqU">Lecture 5: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=N3vJOq5ZmKc">Lecture 6: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=t0MmgkV4YrA">Lecture 7: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=dLp2m9ae_MQ">Lecture 8: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=Kwli6FkYQYY">Lecture 9: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=rAGMDhz23Aw">Lecture 10: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=upMWYV7S1Y0">Lecture 11: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=cHVpwyYU_LY">Lecture 12: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=E4gl91l0l40">Lecture 13: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=QsfQAPdxeyw">Lecture 14: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=DsXzUU691ts">Lecture 15: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=1A734g96Npk">Lecture 16: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=TzY09ZfmOUI">Lecture 17: Convex Optimization II</a>
			</li>
			<li>
				<a href="http://www.youtube.com/watch?v=ORo5IU9a55s">Lecture 18: Convex Optimization II</a>
			</li>
		</ul>
		<p>
			A <a href="http://www.youtube.com/view_play_list?p=3940DD956CDF0622">play list</a> is available too.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-08T07:12:45-07:00">May 8, 2013</time>
			</div>
			<h1><a href="post/2013/05/08/stein_paradox_in_statistics/">Stein's Paradox in Statistics (Bradley Efron, Carl Morris)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://www-stat.stanford.edu/~ckirby/brad/other/Article1977.pdf">
			<p>
				Sometimes a mathematical result is strikingly contrary to generally held belief even though an obviously valid proof is given.
				Charles Stein of Stanford University discovered such as a paradox in statistics in 1955.
				His result undermined a century and a half of work on estimation theory, going back to Karl Friedrich Gauss and Adrien Marie Legendre.
				After a long period of resistance to Stein's ideas, punctuated by frequent and sometimes angry debate, the sense of paradox has diminished and Stein's ideas are being incorporated into applied and theoretical statistics.
			</p>
			<p>
				Stein's paradox concerns the use of observed averages to estimate unobserved quantities.
				Averaging is the second most basic process in statistics, the first being the simple act of counting.
			</p>
			<p>
				[...]
			</p>
			<p>
				The paradoxical element in Stein's result is that it sometimes contradicts this elementary law of statistical theory.
			</p>
		</blockquote>
		<p>
			[<a href="http://www-stat.stanford.edu/~ckirby/brad/other/Article1977.pdf">PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-07T06:11:54-07:00">May 7, 2013</time>
			</div>
			<h1><a href="post/2013/05/07/hadley_alexander_wickham_vancouver/">TOMORROW: Hadley Alexander Wickham: Speaking at Vancouver Meetup on Wednesday May 8th at 7:00 PM</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Tomorrow is the day.
		</p>
		<p>
			<a href="http://www.r-project.org/">R</a> users are likely to know the name:
			<a href="http://had.co.nz/">Hadley Alexander Wickham</a>.
		</p>
		<p>
			Hadley will be in Vancouver tomorrow, and will be speaking at a combined meetup event for the 
			Vancouver-based <a href="http://www.meetup.com/DataScience/events/114687772/">Data Science group</a>
			and the <a href="http://www.meetup.com/Vancouver-R-Users-Group-data-analysis-statistics/events/114670912/">Vancouver R user group</a>.
		</p>
		<p>
			If you are in the Vancouver area, use R, or are interested in statistics or visualization, be there tomorrow.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-06T07:23:46-07:00">May 6, 2013</time>
			</div>
			<h1><a href="post/2013/05/06/signals_and_systems/">Video Lectures: Signals and Systems, by Alan V. Oppenheim</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://www.rle.mit.edu/people/directory/alan-oppenheim/">Alan V. Oppenheim</a>
			has a number of <a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/">video lectures</a>
			on: <a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/">Signals and Systems</a> (up on MIT OpenCourseWare).
		</p>
		<p>
			 Here is the complete list of video lectures:
		</p>
		<ul>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-1-introduction">Lecture 1: Introduction</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-2-signals-and-systems-part-i">Lecture 2: Signals and Systems: Part I</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-3-signals-and-systems-part-ii">Lecture 3: Signals and Systems: Part II</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-4-convolution">Lecture 4: Convolution</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-5-properties-of-linear-time-invariant-systems">Lecture 5: Properties of Linear, Time-Invariant Systems</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-6-systems-represented-by-differential-equations">Lecture 6: Systems Represented by Differential Equations</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-7-continuous-time-fourier-series">Lecture 7: Continuous-Time Fourier Series</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-8-continuous-time-fourier-transform">Lecture 8: Continuous-Time Fourier Transform</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-9-fourier-transform-properties">Lecture 9: Fourier Transform Properties</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-10-discrete-time-fourier-series">Lecture 10: Discrete-Time Fourier Series</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-11-discrete-time-fourier-transform">Lecture 11: Discrete-Time Fourier Transform</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-12-filtering">Lecture 12: Filtering</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-13-continuous-time-modulation">Lecture 13: Continuous-Time Modulation</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-14-demonstration-of-amplitude-modulation">Lecture 14: Demonstration of Amplitude Modulation</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-15-discrete-time-modulation">Lecture 15: Discrete-Time Modulation</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-16-sampling">Lecture 16: Sampling</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-17-interpolation">Lecture 17: Interpolation</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-18-discrete-time-processing-of-continuous-time-signals">Lecture 18: Discrete-Time Processing of Continuous-Time Signals</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-19-discrete-time-sampling">Lecture 19: Discrete-Time Sampling</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-20-the-laplace-transform">Lecture 20: The Laplace Transform</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-21-continuous-time-second-order-systems">Lecture 21: Continuous-Time Second-Order Systems</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-22-the-z-transform">Lecture 22: The z-Transform</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-23-mapping-continuous-time-filters-to-discrete-time-filters">Lecture 23: Mapping Continuous-Time Filters to Discrete-Time Filters</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-24-butterworth-filters">Lecture 24: Butterworth Filters</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-25-feedback">Lecture 25: Feedback</a>
			</li>
			<li>
				<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/video-lectures/lecture-26-feedback-example-the-inverted-pendulum">Lecture 26: Feedback Example: The Inverted Pendulum</a>
			</li>
		</ul>
		<p>
			To get the most out of the video lectures, it would probably be a good idea to work through the
			<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/assignments">assignments</a>
			and
			<a href="http://ocw.mit.edu/resources/res-6-007-signals-and-systems-spring-2011/readings">readings</a> too.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-05T07:36:27-07:00">May 5, 2013</time>
			</div>
			<h1><a href="post/2013/05/05/nonlinear_dimensionality_reduction/">A Global Geometric Framework for Nonlinear Dimensionality Reduction (Joshua B. Tenenbaum, Vin de Silva, John C. Langford)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://www.robots.ox.ac.uk/~az/lectures/ml/tenenbaum-isomap-Science2000.pdf">
			<p>
				Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations.
				The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 10<sup>6</sup> optic nerve fibers—a manageably small number of perceptually relevant features.
				Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set.
				Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions.
				In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.
			</p>
		</blockquote>
		<p>
			[<a href="http://www.robots.ox.ac.uk/~az/lectures/ml/tenenbaum-isomap-Science2000.pdf">PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-05-04T09:46:35-07:00">May 4, 2013</time>
			</div>
			<h1><a href="post/2013/05/04/revealing_social_networks/">Revealing social networks of spammers through spectral clustering (Kevin S. Xu, Mark Kliger, Yilun Chen, Peter J. Woolf, Alfred O. Hero III)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://arxiv.org/abs/1305.0051">
			<p>
				To date, most studies on spam have focused only on the spamming phase of the spam cycle and have ignored the harvesting phase, which consists of the mass acquisition of email addresses.
				It has been observed that spammers conceal their identity to a lesser degree in the harvesting phase, so it may be possible to gain new insights into spammers' behavior by studying the behavior of harvesters, which are individuals or bots that collect email addresses.
				In this paper, we reveal social networks of spammers by identifying communities of harvesters with high behavioral similarity using spectral clustering.
				The data analyzed was collected through Project Honey Pot, a distributed system for monitoring harvesting and spamming.
				Our main findings are (1) that most spammers either send only phishing emails or no phishing emails at all, (2) that most communities of spammers also send only phishing emails or no phishing emails at all, and (3) that several groups of spammers within communities exhibit coherent temporal behavior and have similar IP addresses.
				Our findings reveal some previously unknown behavior of spammers and suggest that there is indeed social structure between spammers to be discovered.
			</p>
		</blockquote>
		<p>
			<a href="http://arxiv.org/abs/1305.0051">arXiv:1305.0051</a> [cs.SI]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-26T07:08:21-07:00">April 26, 2013</time>
			</div>
			<h1><a href="post/2013/04/26/jsnetworkx/">JSNetworkX: Visualizing Graphs On The Web Using JavaScript</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Visualizing graphs (in the <em>graph theory</em> sense of the word) can be a challenge.
			Visualizing graphs on the web can be a even bigger challenge.
			Luckily there is <a href="http://felix-kling.de/JSNetworkX/">JSNetworkX</a>.
		</p>
		<p>
			JSNetworkX is an open source JavaScript library that makes visualizing graph data easy.
		</p>
		<p>
			JSNetwork is a port of the <a href="http://networkx.github.io/">NetworkX</a> graph visualization library 
			to JavaScript and the Web
			(using <a href="http://d3js.org/">D3</a>).
		</p>
		<p>
			Here is an example, as shown in <em>figure 1</em>.
		</p>
		<figure>
			<div id="jsnetworkx_20130426_1" style="border:1px solid black;height:220px;"></div>
			<script>
			$(document).ready(function() {

					var G = jsnx.Graph();
     
					G.add_nodes_from([1,2,3,4], {group:0});
					G.add_nodes_from([5,6,7], {group:1});
					G.add_nodes_from([8,9,10,11], {group:2});
     
					G.add_path([1,2,5,6,7,8,11]);
					G.add_edges_from([[1,3],[1,4],[3,4],[2,3],[2,4],[8,9],[8,10],[9,10],[11,10],[11,9]]);
     
					var color = d3.scale.category20();
					jsnx.draw(G, {
						element: '#jsnetworkx_20130426_1',
						layout_attr: {
							charge: -120,
							linkDistance: 20
						},
						node_attr: {
							r: 5,
							title: function(d) { return d.label;}
						},
						node_style: {
							fill: function(d) {
								return color(d.data.group);
							},
							stroke: 'none'
						},
						edge_style: {
						fill: '#999'
					}
				});

			});
			</script>
			<figcaption>
				<b>Figure 1.</b>
				Sample graph visualization created with JSNetworkX.
			</figcaption>
		</figure>
		<p>
			And here is the code for the graph visualization in <em>figure 1</em>, as shown in <em>figure 2</em>.
		</p>
		<figure>
			<pre><code>
var G = jsnx.Graph();
     
G.add_nodes_from([1,2,3,4], {group:0});
G.add_nodes_from([5,6,7], {group:1});
G.add_nodes_from([8,9,10,11], {group:2});
     
G.add_path([1,2,5,6,7,8,11]);
G.add_edges_from([[1,3],[1,4],[3,4],[2,3],[2,4],[8,9],[8,10],[9,10],[11,10],[11,9]]);
     
var color = d3.scale.category20();
jsnx.draw(G, {
  element: '#PUT_IT_OF_WHERE_TO_RENDER_THE_GRAPH_HERE',
  layout_attr: {
    charge: -120,
    linkDistance: 20
  },
  node_attr: {
    r: 5,
    title: function(d) { return d.label;}
  },
  node_style: {
    fill: function(d) {
      return color(d.data.group);
    },
    stroke: 'none'
  },
  edge_style: {
    fill: '#999'
  }
});
			</code></pre>
			<figcaption>
				<b>Figure 2.</b>
				JavaScript source code using JSNetworkX for the graph visualization shown in <em>figure 1</em>.
			</figcaption>
		</figure>
		<p>
			More information about
			<a href="http://felix-kling.de/JSNetworkX/">JSNetworkX</a>
			is available
			<a href="http://felix-kling.de/JSNetworkX/">here</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-24T07:17:48-07:00">April 24, 2013</time>
			</div>
			<h1><a href="post/2013/04/24/networks_crowds_and_markets/">Networks, Crowds, and Markets: Reasoning About a Highly Connected World (David Easley, Jon Kleinberg)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<img src="../../../../../data/post/2013/04/24/networks_crowds_and_markets/networks_crowds_and_markets.jpg" align="right" style="width:240px;"/>
			<a href="http://www.arts.cornell.edu/econ/deasley/">David Easley</a>
			and
			<a href="http://www.cs.cornell.edu/home/kleinber/">Jon Kleinberg</a>
			have created an <i>excellent</i> book on (a subset of graph theory known as) small-world networks and their applications, such as social networks.
			Although that description probably doesn't do the book justice.
			(The book is definitely worth a read.)
		</p>
		<p>
			It is called:
			<a href="http://www.cs.cornell.edu/home/kleinber/networks-book/">Networks, Crowds, and Markets: Reasoning About a Highly Connected World</a>.
		</p>
		<p>
			You can either <a href="http://www.cambridge.org/us/networksbook">buy a copy here</a>
			or <a href="http://www.cs.cornell.edu/home/kleinber/networks-book/">download it for free</a>.
		</p>
		<p>
			Here is their description of it:
		</p>
		<blockquote cite="http://www.cs.cornell.edu/home/kleinber/networks-book/">
			<p>
				Over the past decade there has been a growing public fascination with the complex "connectedness" of modern society. This connectedness is found in many incarnations: in the rapid growth of the Internet and the Web, in the ease with which global communication now takes place, and in the ability of news and information as well as epidemics and financial crises to spread around the world with surprising speed and intensity. These are phenomena that involve networks, incentives, and the aggregate behavior of groups of people; they are based on the links that connect us and the ways in which each of our decisions can have subtle consequences for the outcomes of everyone else.
			</p>
			<p>
				<i>Networks, Crowds, and Markets</i> combines different scientific perspectives in its approach to understanding networks and behavior. Drawing on ideas from economics, sociology, computing and information science, and applied mathematics, it describes the emerging field of study that is growing at the interface of all these areas, addressing fundamental questions about how the social, economic, and technological worlds are connected.
			</p>
		</blockquote>
		<p>
			[<a href="http://www.cs.cornell.edu/home/kleinber/networks-book/">HTML + PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-22T07:28:02-07:00">April 22, 2013</time>
			</div>
			<h1><a href="post/2013/04/22/analysing_mood_patterns/">Analysing Mood Patterns in the United Kingdom through Twitter Content (Vasileios Lampos, Thomas Lansdall-Welfare, Ricardo Araya, Nello Cristianini)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://arxiv.org/abs/1304.5507">
			<p>
				Social Media offer a vast amount of geo-located and time-stamped textual content directly generated by people.
				This information can be analysed to obtain insights about the general state of a large population of users and to address scientific questions from a diversity of disciplines.
				In this work, we estimate temporal patterns of mood variation through the use of emotionally loaded words contained in Twitter messages, possibly reflecting underlying circadian and seasonal rhythms in the mood of the users.
				We present a method for computing mood scores from text using affective word taxonomies, and apply it to millions of tweets collected in the United Kingdom during the seasons of summer and winter.
				Our analysis results in the detection of strong and statistically significant circadian patterns for all the investigated mood types.
				Seasonal variation does not seem to register any important divergence in the signals, but a periodic oscillation within a 24-hour period is identified for each mood type.
				The main common characteristic for all emotions is their mid-morning peak, however their mood score patterns differ in the evenings.
			</p>
		</blockquote>
		<p>
			<a href="http://arxiv.org/abs/1304.5507">arXiv:1304.5507</a> [cs.SI]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-21T09:45:23-07:00">April 21, 2013</time>
			</div>
			<h1><a href="post/2013/04/21/plos_text_mining_collection/">New: PLOS Text Mining</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			The folks over at <a href="http://www.plos.org/">PLOS</a> are introducing the <a href="http://www.ploscollections.org/textmining">PLOS Text Mining Collection</a>.
		</p>
		<blockquote cite="http://blogs.plos.org/everyone/2013/04/17/announcing-the-plos-text-mining-collection/">
			<p>
				Text Mining is an interdisciplinary field combining techniques from linguistics, computer science and statistics to build tools that can efficiently retrieve and extract information from digital text.
				Over the last few decades, there has been increasing interest in text mining research because of the potential commercial and academic benefits this technology might enable.
			</p>
			<p>
				[...]
			</p>
			<p>
				First, the rate of growth of the scientific literature has now outstripped the ability of individuals to keep pace with new publications, even in a restricted field of study.
				Second, text-mining tools have steadily increased in accuracy and sophistication to the point where they are now suitable for widespread application.
				Finally, the rapid increase in availability of digital text in an Open Access format now permits text-mining tools to be applied more freely than ever before.
			</p>
			<p>
				[...]
			</p>
			<p>
				PLOS launches the <a href="http://www.ploscollections.org/textmining">Text Mining Collection</a>, a compendium of major reviews and recent highlights published in the PLOS family of journals on the topic of text mining.
				As one of the major publishers of the Open Access scientific literature, it is perhaps no coincidence that research in text mining in PLOS journals is flourishing.
				As noted above, the widespread application and societal benefits of text mining is most easily achieved under an Open Access model of publishing, where the barriers to obtaining published articles are minimized and the ability to remix and redistribute data extracted from text is explicitly permitted.
				Furthermore, PLOS is one of the few publishers who is actively promoting text mining research by providing an open <a href="http://api.plos.org/">Application Programming Interface</a> to mine their journal content.
			</p>
		</blockquote>
		<p>
			See it <a href="http://www.ploscollections.org/textmining">here</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-19T06:15:44-07:00">April 19, 2013</time>
			</div>
			<h1><a href="post/2013/04/19/information_theory_pattern_recognition_and_neural_networks/">Video Lectures: Information Theory, Pattern Recognition, and Neural Networks, by David J. C. MacKay</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://www.inference.phy.cam.ac.uk/mackay/">David J.C. MacKay</a> has a number of
			<a href="http://videolectures.net/course_information_theory_pattern_recognition/">video lectures</a>
			available on:
			<a href="http://videolectures.net/course_information_theory_pattern_recognition/">Information Theory, Pattern Recognition, and Neural Networks</a>.
		</p>
		<p>
			Here is the complete list of video lectures:
		</p>
		<ul>
			<li>
				<a href="http://videolectures.net/mackay_course_01/">Lecture 1: Introduction to Information Theory</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_02/">Lecture 2: Entropy and Data Compression (I): Introduction to Compression, Information Theory and Entropy</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_03/">Lecture 3: Entropy and Data Compression (II): Shannon's Source Coding Theorem and the Bent Coin Lottery</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_04/">Lecture 4: Entropy and Data Compression (III): Shannon's Source Coding Theorem, Symbol Codes</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_05/">Lecture 5: Entropy and Data Compression (IV): Shannon's Source Coding Theorem, Symbol Codes and Arithmetic Coding</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_06/">Lecture 6: Noisy Channel Coding (I): Inference and Information Measures for Noisy Channels</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_07/">Lecture 7: Noisy Channel Coding (II): The Capacity of a Noisy Channel</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_08/">Lecture 8: Noisy Channel Coding (III): The Noisy-Channel Coding Theorem</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_09/">Lecture 9: A Noisy Channel Coding Gem, And An Introduction To Bayesian Inference (I)</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_10/">Lecture 10: An Introduction To Bayesian Inference (II): Inference Of Parameters And Models</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_11/">Lecture 11: Approximating Probability Distributions (I): Clustering As An Example Inference Problem</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_12/">Lecture 12: Approximating Probability Distributions (II): Monte Carlo Methods (I): Importance Sampling, Rejection Sampling, Gibbs Sampling, Metropolis Method</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_13/">Lecture 13: Approximating Probability Distributions (III): Monte Carlo Methods (II): Slice Sampling, Hybrid Monte Carlo, Over-relaxation, Exact Sampling </a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_14/">Lecture 14: Approximating Probability Distributions (IV): Variational Methods</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_15/">Lecture 15: Data Modelling With Neural Networks (I): Feedforward Networks: The Capacity Of A Single Neuron, Learning As Inference</a>
			</li>
			<li>
				<a href="http://videolectures.net/mackay_course_16/">Lecture 16: Data Modelling With Neural Networks (II): Content-Addressable Memories And State-Of-The-Art Error-Correcting Codes</a>
			</li>
		</ul>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-18T07:02:36-07:00">April 18, 2013</time>
			</div>
			<h1><a href="post/2013/04/18/hadley_alexander_wickham_vancouver/">Hadley Alexander Wickham: Speaking at Vancouver Meetup on Wednesday May 8th at 7:00 PM</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			For those who use <a href="http://www.r-project.org/">R</a>, the name
			<a href="http://had.co.nz/">Hadley Alexander Wickham</a> is a well known one.
		</p>
		<p>
			Hadley is coming to Vancouver, and will be speaking at a combined meetup event for the 
			Vancouver-based <a href="http://www.meetup.com/DataScience/events/114687772/">Data Science group</a>
			and the <a href="http://www.meetup.com/Vancouver-R-Users-Group-data-analysis-statistics/events/114670912/">Vancouver R user group</a>.
		</p>
		<p>
			If you are in the Vancouver area, use R, or are interested in statistics or visualization, you should be there.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-17T07:27:54-07:00">April 17, 2013</time>
			</div>
			<h1><a href="post/2013/04/17/tools_for_exploring_data_and_models/">Practical Tools For Exploring Data And Models (Hadley Alexander Wickham)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://had.co.nz/thesis/">
			<p>
				This thesis describes three families of tools for exploring data and models.
				It is organised in roughly the same way that you perform a data analysis.
				First, you get the data in a form that you can work with.
				Chapter 2 describes the reshape framework for restructuring data.
				Second, you plot the data to get a feel for what is going on.
				Chapter 3 introduces the layered grammar of graphics.
				Third, you iterate between graphics and models to build a succinct quantitative summary of the data.
				Chapter 4 introduces some strategies for visualising models.
				Finally, you look back at what you have done, and contemplate what tools you need to do better in the future.
				Chapter 5 summarises the impact of my work and my plans for the future.
			</p>
		</blockquote>
		<p>
			[<a href="http://had.co.nz/thesis/practical-tools-hadley-wickham.pdf">PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-16T07:04:17-0700">April 16, 2013</time>
			</div>
			<h1><a href="post/2013/04/16/spark_cli_graphs/">Sprak: Graph Visualization From The Command Line</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			So you are at the command line.
			You have a bunch of data you pulled from the database or a file.
			You did a bunch of "magic" to <code>awk</code>, <code>sort</code> and other command line tools to extract the "important" parts of the data.
		</p>
		<p>
			Now you want to see that "important" extract in a graph.
		</p>
		<p>
			What's the fastest way to visualize it?
			What's the fastest to see a graph?
		</p>
		<p>
			MS Excel?
			OpenOffice Calc?
			GNU Octave?
			R?
		</p>
		<p>
			No, no, no and no.
		</p>
		<p>
			The fastest way is using  <a href="http://zachholman.com/spark/">spark</a>.
		</p>
		<p>
			 <a href="http://zachholman.com/spark/">Spark</a>  lets you create and view graphs right from the command line.
		</p>
		<p>
			Here is a very basic example:
		</p>
		<figure>
			<figcaption>
				<pre><code>
spark 0 30 55 80 33 150
				</code></pre>
				<strong>Figure 1.</strong>
				Very basic usage of <code>spak</code>.
			</figcaption>
		</figure>
		<figure>
			<figcaption>
				<pre><code>
▁▂▃▅▂▇
				</code></pre>
				<strong>Figure 2.</strong>
				Output of <code>spark</code> command in <em>figure 1</em>.
			</figcaption>
		</figure>
		<p>
			And here is a more typical example:
		</p>
		<figure>
			<figcaption>
				<pre><code>
curl http://earthquake.usgs.gov/earthquakes/catalogs/eqs1day-M1.txt --silent | sed '1d' | cut -d, -f9 | spark
				</code></pre>
				<strong>Figure 3.</strong>
				More typical usage of <code>spak</code>.
				Magnitude of earthquakes over 1.0 in the last 24 hours.
			</figcaption>
		</figure>
		<figure>
			<figcaption>
				<pre><code>
 ▅▆▂▃▂▂▂▅▂▂▅▇▂▂▂▃▆▆▆▅▃▂▂▂▁▂▂▆▁▃▂▂▂▂▃▂▆
				</code></pre>
				<strong>Figure 4.</strong>
				Output of <code>spark</code> command in <em>figure 3</em>.
			</figcaption>
		</figure>
		<p>
			(<a href="https://github.com/holman/spark/wiki/Wicked-Cool-Usage">More spark examples here</a>.)
		</p>
		<p>
			Check out <a href="http://zachholman.com/spark/">spark</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-15T06:59:44-0700">April 15, 2013</time>
			</div>
			<h1><a href="post/2013/04/15/ontario_open_data/">We Love Open Data: Ontario Open Data</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			The "currency" of a <em>data scientist</em>'s vocation is (surprise, surprise) <em>data</em>.
			Sometimes data scientists have to go to great lengths to gather the data sets themselves.
			And sometimes people will "give" it to them. 
		</p>
		<p>
			The government of Ontario has done just that.
		</p>
		<p>
			Meet the <a href="http://www.ontario.ca/government/government-ontario-open-data">Ontario Open Data portal</a>.
		</p>
		<p>
			Explore the data sets they offer yourself.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-13T12:34:25-07:00">April 13, 2013</time>
			</div>
			<h1><a href="post/2013/04/13/strong_ties/">The emergence and role of strong ties in time-varying communication networks (Márton Karsai, Nicola Perra, Alessandro Vespignani)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://arxiv.org/abs/1303.5966">
			<p>
				In most social, information, and collaboration systems the complex activity of agents generates rapidly evolving time-varying networks.
				Temporal changes in the network structure and the dynamical processes occurring on its fabric are usually coupled in ways that still challenge our mathematical or computational modelling.
				Here we analyse a mobile call dataset describing the activity of millions of individuals and investigate the temporal evolution of their egocentric networks.
				We empirically observe a simple statistical law characterizing the memory of agents that quantitatively signals how much interactions are more likely to happen again on already established connections.
				We encode the observed dynamics in a reinforcement process defining a generative computational network model with time-varying connectivity patterns.
				This activity-driven network model spontaneously generates the basic dynamic process for the differentiation between strong and weak ties.
				The model is used to study the effect of time-varying heterogeneous interactions on the spreading of information on social networks.
				We observe that the presence of strong ties may severely inhibit the large scale spreading of information by confining the process among agents with recurrent communication patterns.
				Our results provide the counterintuitive evidence that strong ties may have a negative role in the spreading of information across networks.
			</p>
		</blockquote>
		<p>
			<a href="http://arxiv.org/abs/1303.5966">arXiv:1303.5966</a> [physics.soc-ph]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-11T09:16:13-07:00">April 11, 2013</time>
			</div>
			<h1><a href="post/2013/04/11/node_centrality_in_weighted_networks/">Node Centrality in Weighted Networks: Generalizing Degree and Shortest Paths (Tore Opsahl, Filip Agneessens, John Skvoretz)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://toreopsahl.files.wordpress.com/2010/04/node_centrality_in_weighted_networks1.pdf">
			<p>
				Ties often have a strength naturally associated with them that differentiate them from each other.
				Tie strength has been operationalized as weights.
				A few network measures have been proposed for weighted networks, including three common measures of node centrality: degree, closeness, and betweenness.
				However, these generalizations have solely focused on tie weights, and not on the number of ties, which was the central component of the original measures.
				This paper proposes generalizations that combine both these aspects.
				We illustrate the benets of this approach by applying one of them to Freeman's EIES dataset.
			</p>
		</blockquote>
		<p>
			[<a href="http://toreopsahl.files.wordpress.com/2010/04/node_centrality_in_weighted_networks1.pdf">PDF</a>]
		</p>
		<p>
			Also see <a href="http://toreopsahl.com/2010/04/21/article-node-centrality-in-weighted-networks-generalizing-degree-and-shortest-paths/">article</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-10T09:35:40-07:00">April 10, 2013</time>
			</div>
			<h1><a href="post/2013/04/10/book_regret_analysis/">Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems (Sébastien Bubeck, Nicolò Cesa-Bianchi)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<img src="data/post/2013/04/10/book_regret_analysis/regret_analysis_of_stochastic_and_nonstochastic_multi-armed_bandit_problems.jpg" align="right" style="width:240px;"/>
			<a href="http://www.princeton.edu/~sbubeck/">Sébastien Bubeck</a> and <a href="http://homes.di.unimi.it/~cesabian/">Nicolò Cesa-Bianchi</a>
			have put out a book on <em>optimization</em> that will be of interest to many readers.
		</p>
		<p>
			It is called:
			<a href="http://www.princeton.edu/~sbubeck/SurveyBCB12.pdf">Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems</a>.
		</p>
		<p>
			You can either <a href="http://www.nowpublishers.com/product.aspx?product=MAL&amp;doi=2200000024">buy a copy here</a> (discount code: MAL022024)
			or <a href="http://www.princeton.edu/~sbubeck/SurveyBCB12.pdf">download it for free here</a>.
		</p>
		<p>
			Here's the authors' description:
		</p>
		<blockquote cite="http://www.princeton.edu/~sbubeck/SurveyBCB12.pdf">
			<p>
				Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration–exploitation trade-off.
				This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future.
				Although the study of bandit problems dates back to the 1930s, exploration–exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing.
				Mathematically, a multi-armed bandit is defined by the payoff process associated with each option.
				In this monograph, we focus on two extreme cases in which the analysis of regret is particularly simple and elegant: i.i.d. payoffs and adversarial payoffs.
				Besides the basic setting of finitely many actions, we also analyze some of the most important variants and extensions, such as the contextual bandit model.
			</p>
		</blockquote>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-09T18:48:51-07:00">April 9, 2013</time>
			</div>
			<h1><a href="post/2013/04/09/polyglot_unconference_2013/">PolyGlot (Un)Conference 2013</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://polyglotconf.com/"><img src="data/post/2013/04/09/polyglot_unconference_2013/polyglot.png" align="right" style="width:200px;"/></a>
			The popular <a href="http://polyglotconf.com/">PolyGlot (Un)Conference</a> is happening on
			Friday May 24th to Sunday May 26th
			in Vancouver.
			<a href="http://polyglotconf.com/tickets/">Tickets are on sale</a> now.
		</p>
		<p>
			If you are in Vancouver, and you are a <em>software engineer</em> or <em>data scientist</em>, you should be there.
			(I'll be there.)
		</p>
		<p>
			Here's the schedule:
		</p>
		<ul>
			<li>
				Friday, May 24th, 2013: Tutorials
			</li>
			<li>
				Saturday, May 25th, 2013: Unconference
			</li>
			<li>
				Sunday, May 26th, 2013: Open Hack Day 
			</li>
		</ul>
		<p>
			If you can only make it one day, be there on <strong>Saturday, May 25th</strong>.
			(But obviously, the more days you can be there, the more you will get out of it.)
		</p>
		<p>
			There will be something on data science, machine learning and artificial intelligence there.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-08T08:38:03-07:00">April 8, 2013</time>
			</div>
			<h1><a href="post/2013/04/08/twitter_who_to_follow/">WTF: The Who to Follow Service at Twitter (Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, Reza Zadeh)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://www.stanford.edu/~rezab/papers/wtf_overview.pdf">
			<p>
				WTF ("Who to Follow") is Twitter's user recommendation service, which is responsible for creating millions of connections daily between users based on shared interests, common connections, and other related factors.
				This paper provides an architectural overview and shares lessons we learned in building and running the service over the past few years.
				Particularly noteworthy was our design decision to process the entire Twitter graph in memory on a single server, which signicantly reduced architectural complexity and allowed us to develop and deploy the service in only a few months.
				At the core of our architecture is Cassovary, an open-source in-memory graph processing engine we built from scratch for WTF.
				Besides powering Twitter's user recommendations, Cassovary is also used for search, discovery, promoted products, and other services as well.
				We describe and evaluate a few graph recommendation algorithms implemented in Cassovary, including a novel approach based on a combination of random walks and SALSA.
				Looking into the future, we revisit the design of our architecture and comment on its limitations, which are presently being addressed in a second-generation system under development.
			</p>
		</blockquote>
		<p>
			[<a href="http://www.stanford.edu/~rezab/papers/wtf_overview.pdf">PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-07T08:40:32-07:00">April 7, 2013</time>
			</div>
			<h1><a href="post/2013/04/07/chaotic_boltzmann_machines/">Chaotic Boltzmann machines (Hideyuki Suzuki, Jun-ichi Imura, Yoshihiko Horio, Kazuyuki Aihara)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote>
			<p>
				The chaotic Boltzmann machine proposed in this paper is a chaotic pseudo-billiard system that works as a Boltzmann machine.
				Chaotic Boltzmann machines are shown numerically to have computing abilities comparable to conventional (stochastic) Boltzmann machines.
				Since no randomness is required, efficient hardware implementation is expected.
				Moreover, the ferromagnetic phase transition of the Ising model is shown to be characterised by the largest Lyapunov exponent of the proposed system.
				In general, a method to relate probabilistic models to nonlinear dynamics by derandomising Gibbs sampling is presented.
			</p>
		</blockquote>
		<p>
			<a href="http://dx.doi.org/10.1038/srep01610">10.1038/srep01610</a>
			<!-- http://www.nature.com/srep/2013/130405/srep01610/full/srep01610.html -->
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-05T06:57:47-07:00">April 5, 2013</time>
			</div>
			<h1><a href="post/2013/04/05/r_3_released/">R 3.0.0 Released</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://www.r-project.org/">R</a> is a popular environment for statistical computing and graphics.
			<a href="https://stat.ethz.ch/pipermail/r-announce/2013/000559.html">R version 3.0.0 has been released.</a>
		</p>
		<p>
			From the release e-mail:
		</p>
		<blockquote cite="https://stat.ethz.ch/pipermail/r-announce/2013/000559.html">
			<p>
				Major R releases have not previously marked great landslides in terms of new features. Rather, they represent that the codebase has developed to a new level of maturity. This is not going to be an exception to the rule.
			</p>
			<p>
				Version 1.0.0 was released at a point in time when we felt that we had reached a level of completeness and stability high enough to characterize a full statistical system, which could be put to production use. 
			</p>
			<p>
				Version 2.0.0 came out after strong enhancements of the memory management subsystem as well as several major features, including Sweave.
			</p>
			<p>
				Version 3.0.0, as of this writing, contains only really major new feature: The inclusion of long vectors (containing more than 2^31-1 elements!). More changes are likely to make it into the final release, but the main reason for having it as a new major release is that R over the last 8.5 years has reached a new level: we now have 64 bit support on all platforms, support for parallel processing, the Matrix package, and much more.
			</p>
		</blockquote>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-04T07:38:07-07:00">April 4, 2013</time>
			</div>
			<h1><a href="post/2013/04/04/josh_wills_data_scientist_definition/">Josh Wills: Data Scientist Definition</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			A definition of what a data scientist is from <a href="http://twitter.com/josh_wills">Josh Wills</a>:
		</p>
		<blockquote cite="http://twitter.com/josh_wills/status/198093512149958656">
			<a href="http://twitter.com/josh_wills/status/198093512149958656"><img src="data/post/2013/04/04/josh_wills_data_scientist_definition/josh_wills_tweet.png" alt="Data Scientist (n.): Person who is better at statistics than any software engineer and better at software engineering than any statistician."/></a>
		</blockquote>
		<p>
			(Sometimes I think <em>data engineer</em> might be a better name for it.)
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-03T07:14:42-07:00">April 3, 2013</time>
			</div>
			<h1><a href="post/2013/04/03/book_elements_of_statistical_learning/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Trevor Hastie, Robert Tibshirani, Jerome Friedman)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<img src="data/post/2013/04/03/book_elements_of_statistical_learning/CoverII_small.jpg" align="right" style="width:240px;"/>
			Statistics is a fundamental part of our vocation.
			<em>We live it and breathe it</em>, so to speak.
		</p>
		<p>
			Thus, interesting books on statistics tend to catch my attention.
			And when they are also freely available, even better :-)
			(Although with this book, you can also buy a copy of it, and help the authors out.)
		</p>
		<p>
			One such book that seems worth a read is:
			<a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>.
		</p>
		<p>
			The book is written by
			<a href="http://www-stat.stanford.edu/~hastie/">Trevor Hastie</a>,
			<a href="http://www-stat.stanford.edu/~tibs/">Robert Tibshirani</a>
			and
			<a href="http://www-stat.stanford.edu/~jhf">Jerome Friedman</a>,
			who have made the book <a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/download.html">available both as a free download and for sale</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-02T06:11:56-07:00">April 2, 2013</time>
			</div>
			<h1><a href="post/2013/04/02/yelp_dataset_challenge/">Yelp Dataset Challenge; And A New Data Set To Play With</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Yelp has made a new data set available with their <a href="http://www.yelp.com/dataset_challenge/">yelp dataset challenge</a>.
		</p>
		<p>
			Get it <a href="http://www.yelp.com/dataset_challenge/">here</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-04-01T07:39:33-07:00">April 1, 2013</time>
			</div>
			<h1><a href="post/2013/04/01/download_twitter_archives/">Many Downloadable Twitter Archives Available For Researchers</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Researchers rejoice.
			Through the work of 
			<a href="http://www.dcc.uchile.cl/node/465">Bárbara Poblete</a> (<a href="http://twitter.com/bpoblete/">@bpoblete</a>),
			<a href="http://www.di.uniovi.es/~dani/">Daniel Gayo-Avello</a> (<a href="http://twitter.com/PFCdgayo/">@PFCdgayo</a>)
			and
			<a href="http://graves.cl/">Álvaro Graves</a> (<a href="http://twitter.com/alvarograves/">@alvarograves</a>)
			there are <a href="http://tweetsforscience.org/">number of full Twitter tweet archives available to download</a>.
			Get them at <a href="http://tweetsforscience.org/">#Tweets4Science</a>
		</p>
		<p>
			(Also, if you are so inclined, consider donating your Twitter tweet archive too.)
		</p>
		<p>
			Now I do think that these Twitter archives will likely be unrepresentative in a lot of ways.
			So keep that in mind as you look at them.
			But nonetheless they still can be useful.
		</p>
		<p>
			It actually wasn't too long ago that one could just go to Twitter and pull people's full tweet archives.
			But Twitter has become more restricitive with their API and data access.
			So archives like these are becoming more and more important.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-31T14:44:32-07:00">March 31, 2013</time>
			</div>
			<h1><a href="http://datascholars.com/post/2013/03/31/don_turnbull_book_recommendations/">Don Turnbull's Book Recommendations For Data Scientists #datascienceyvr</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Since there has been people asking for it, I thought I'd extract <a href="http://donturn.com/">Don Turnbull</a>'s (<a href="http://twitter.com/donturn">@donturn</a>) book recommendations for data scientists,
			from <a href="http://datascholars.com/post/2013/03/29/don_turnbull_data_science_yvr/"><abbr title="Don Turnbull's">his</abbr> data science talk slides</a>.
		</p>
		<ul>
			<li>
				<h2>Fiction</h2>
				<ul>
					<li>
						<u>Foundation</u>,
						by Isaac Asimov
					</li>
				</ul>
			</li>
			<li>
				<h2>Statistics</h2>
				<ul>
					<li>
						<u>The Control Revolution</u>,
						by James R. Beniger
					</li>
					<li>
						<u>Against the Gods: The Remarkable Story of Risk</u>,
						by Peter L. Bernstein
					</li>
					<li>
						<u>Data Mining: Practical Machine Learning Tools and Techniques</u>,
						by Ian H. Witten and Eibe Frank (and Mark Hall?)
					</li>
					<li>
						<u>The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century</u>,
						by David Salsburg
					</li>
					<li>
						<u>The Laws of the Web: Patterns in the Ecology of Information</u>,
						by Bernardo A. Huberman
					</li>
					<li>
						<u>The Rise of Statistical Thinking, 1820-1900</u>,
						by Theodore M. Porter
					</li>
					<li>
						<u>When Information Came of Age: Technologies of Knowledge in the Age of Reason and Revolution, 1700-1850</u>,
						by Daniel R. Headrick
					</li>
					<li>
						<u>Men of Mathematics</u>,
						by E. T. Bell
					</li>
				</ul>
			</li>
			<li>
				<h2>Knowledge Discovery and Data Mining (KDD)</h2>
				<ul>
					<li>
						<u>Advances in Knowledge Discovery and Data Mining</u>,
						edited by Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth and Ramasamy Uthurusamy
					</li>
					<li>
						<u>Machine Learning</u>,
						by Tom M. Mitchell
					</li>
					<li>
						<u>Readings in Information Visualization: Using Vision to Think</u>,
						by Stuart K. Card, Jock D. Mackinlay and Ben Schneiderman
					</li>
				</ul>
			</li>
		</ul>
	



			</div>
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-30T08:50:17-07:00">March 30, 2013</time>
			</div>
			<h1><a href="post/2013/03/30/visual_analytics_2013-04-04/">Visual Analytics Meetup on April 4th</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://www.meetup.com/Vancouver-iDevelopers/events/111549232/">A meetup on Visual Analytics</a> will be held on <time datetime="2013-04-04">April 4th</time> 
		</p>
		<p>
			If you are in Vancouver on that date, be sure to <a href="http://www.meetup.com/Vancouver-iDevelopers/events/111549232/">check it out</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-30T08:11:19-07:00">March 30, 2013</time>
			</div>
			<h1><a href="post/2013/03/30/new_optimization_blog/">New Blog on Optimization</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			There is a new blog on solving optimization problems by Sébastien Bubeck called: <a href="https://blogs.princeton.edu/imabandit/">I'm a Bandit</a>.
		</p>
		<p>
			You can also follow Sébastien on Twitter here: <a href="http://twitter.com/SebastienBubeck">@SebastienBubeck</a>
		</p>
		<p>
			And get to Sébastien's homepage here: <a href="http://www.princeton.edu/~sbubeck/">http://www.princeton.edu/~sbubeck/</a>
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-29T09:32:55-07:00">March 29, 2013</time>
			</div>
			<h1><a href="post/2013/03/29/don_turnbull_data_science_yvr/">Don Turnbull's Data Science Talk Slides #datascienceyvr</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			If you were at the new <a href="http://datascholars.com/post/2013/03/11/data_science_meetup_vancouver/">Data Science meetup group</a> in Vancouver on <time datetime="2013-03-27">Wednesday</time>,
			then you saw a great introductory Data Science talk by <a href="http://donturn.com/">Don Turnbull</a> (<a href="http://twitter.com/donturn">@donturn</a>).
		</p>
		<p>
			He covered a lot!
			And I think every two slides he put up could have been expanded upon and turned into talks of their own! :-)
		</p>
		<p>
			I wanted to have my video camera ready to film it, but it didn't work out that way.
			But, even without that, Don has made the slides of his talk available.
		</p>
		<p>
			<a rel="enclosure" href="data/post/2013/03/29/don_turnbull_data_science_yvr/donturn-datascienceyvr.pdf">Download</a> them <a rel="enclosure" href="data/post/2013/03/29/don_turnbull_data_science_yvr/donturn-datascienceyvr.pdf">here</a>: 
			<a rel="enclosure" href="data/post/2013/03/29/don_turnbull_data_science_yvr/donturn-datascienceyvr.pdf">donturn-datascienceyvr.pdf</a>
		</p>
		<p>
			Also, if you are not "doing" data science yet and are wondering <em>what is data science</em>, Don's slides are a good place to start.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-28T07:48:21-07:00">March 28, 2013</time>
			</div>
			<h1><a href="post/2013/03/28/sentiment_analysis/">Unsupervised Sentiment Analysis with Emotional Signals (Xia Hu, Jiliang Tang, Huiji Gao, Huan Liu)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<blockquote cite="http://www.public.asu.edu/~xiahu/papers/www13.pdf">
			<p>
				The explosion of social media services presents a great opportunity to understand the sentiment of the public via analyzing its large-scale and opinion-rich data.
				In social media, it is easy to amass vast quantities of unlabeled data, but very costly to obtain sentiment labels, which makes unsupervised sentiment analysis essential for various applications.
				It is challenging for traditional lexicon-based unsupervised methods due to the fact that expressions in social media are unstructured, informal, and fast-evolving.
				Emoticons and product ratings are examples of emotional signals that are associated with sentiments expressed in posts or words.
				Inspired by the wide availability of emotional signals in social media, we propose to study the problem of unsupervised <i>sentiment analysis</i> with <i>emotional signals</i>.
				In particular, we investigate whether the signals can potentially help sentiment analysis by providing a unifed way to model two main categories of emotional signals, i.e., emotion indication and emotion correlation.
				We further incorporate the signals into an unsupervised learning framework for sentiment analysis.
				In the experiment, we compare the proposed framework with the state-of-the-art methods on two Twitter datasets and empirically evaluate our proposed framework to gain a deep understanding of the effects of emotional signals.
			</p>
		</blockquote>
		<p>
			[<a href="http://www.public.asu.edu/~xiahu/papers/www13.pdf">PDF</a>]
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-27T07:32:48-07:00">March 27, 2013</time>
			</div>
			<h1><a href="post/2013/03/27/berkeley_computational_social_science/">New Berkeley Computational Social Science Lab</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			Berkeley has a new <em>computational social science</em> lab call <a href="http://dlab.berkeley.edu/">D-Lab</a>.
		</p>
		<p>
			Be sure to also follow them on Twitter at: <a href="http://twitter.com/DLabAtBerkeley">@DLabAtBerkeley</a>.
			And also follow their <a href="http://dlab.berkeley.edu/blog">blog</a>.
		</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-26T07:47:10-07:00">March 26, 2013</time>
			</div>
			<h1><a href="post/2013/03/26/data_science_for_software_engineers/">Data Science For Software Engineers</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://www.hilarymason.com/">Hilary Mason</a> asked the question on Twitter:
		</p>
		<blockquote cite="http://twitter.com/hmason/status/313426603260669952">
			<a href="http://twitter.com/hmason/status/313426603260669952"><img src="data/post/2013/03/26/data_science_for_software_engineers/hmason_tweet.png" alt="Data people -- what do you think software engineers should know about data science / machine learning?"/></a>
		</blockquote>
		<p>
			There were a number of answers to her question.
			All quoted:
		</p>
		<p>
			From <a href="http://twitter.com/el33th4xor">@el33th4xor</a>:
		</p>
		<blockquote cite="http://twitter.com/el33th4xor/status/313426962452463618">
			<p>
				Hi Hilary, I'm not exactly in that space, but I think the syllabus here is a good start:
				<a href="https://www.cs.cornell.edu/courses/cs4780/2012fa/">https://www.cs.cornell.edu/courses/cs4780/2012fa/</a>
			</p>
		</blockquote>
		<p>
			The syllabus mentioned is:
		</p>
		<blockquote cite="https://www.cs.cornell.edu/courses/cs4780/2012fa/">
			<p>
				Machine learning is concerned with the question of how to make computers learn from experience. The ability to learn is not only central to most aspects of intelligent behavior, but machine learning techniques have become key components of many software systems. For examples, machine learning techniques are used to create spam filters, to analyze customer purchase data, to understand natural language, or to detect fraudulent credit card transactions. 
			</p>
			<p>
				This course will introduce the fundamental set of techniques and algorithms that constitute machine learning as of today, ranging from classification methods like decision trees and support vector machines, over structured models like hidden Markov models, to clustering and matrix factorization methods for recommendation. The course will not only discuss individual algorithms and methods, but also tie principles and approaches together from a theoretical perspective. In particular, the course will cover the following topics:
			</p>
			<ul>
				<li>
					<b>Concept Learning</b> : Hypothesis space, version space 
				</li>
				<li>
					<b>Instance-based Learning</b> : K-Nearest Neighbors, collaborative filtering
				</li>
				<li>
					<b>Decision Trees</b> : TDIDT, attribute selection, pruning and overfitting
				</li>
				<li>
					<b>ML Experimentation</b> : Hypothesis tests, resampling estimates 
				</li>
				<li>
					<b>Linear Rules</b> : Perceptron, duality, mistake bound 
				</li>
				<li>
					<b>Support Vector Machines</b> : Optimal hyperplane, kernels, stability 
				</li>
				<li>
					<b>Generative Models</b> : Naïve Bayes, linear discriminant analysis 
				</li>
				<li>
					<b>Hidden Markov Models</b>: probabilistic model, estimation, Viterbi
				</li>
				<li>
					<b>Structured Output Prediction</b> : predicting sequences, rankings, etc.
				</li>
				<li>
					<b>Learning Theory</b> : PAC learning, mistake bounds, VC dimension 
				</li>
				<li>
					<b>Clustering</b> : HAC, k-means, mixture of Gaussians
				</li>
				<li>
					<b>Recommendation Systems</b>: Similarity based methods, matrix factorization
				</li>
			</ul>
		</blockquote>
		<p>
			From <a href="http://twitter.com/kumar303">@kumar303</a>:
		</p>
		<blockquote cite="http://twitter.com/kumar303/status/313427322143395840">
			<p>
				concurrency
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/techmilind">@techmilind</a>:
		</p>
		<blockquote cite="http://twitter.com/techmilind/status/313427586485198848">
			<p>
				communication patterns and working set sizes for popular ML algos, and interactivity/flexibility requirements for data science
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/honkfestival">@honkfestival</a>:
		</p>
		<blockquote cite="http://twitter.com/honkfestival/status/313427718651912192">
			<p>
				The importance of making evidence-based decisions whenever possible.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/esammer">@esammer</a>:
		</p>
		<blockquote cite="http://twitter.com/esammer/status/313427736469311489">
			<p>
				basic stats, probability, classification, techniques for exploration and description, basic viz. i'm math-dumb and those help me.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/gotoplanb">@gotoplanb</a>:
		</p>
		<blockquote cite="http://twitter.com/gotoplanb/status/313429800679251969">
			<p>
				Sampling error
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/jamesdotcuff">@jamesdotcuff</a>:
		</p>
		<blockquote cite="http://twitter.com/jamesdotcuff/status/313430221292457984">
			<p>
				being able to parse really messy input data - the algorithm is often cake in comparison ref: human genome ;-)
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/mdreid">@mdreid</a>:
		</p>
		<blockquote cite="http://twitter.com/mdreid/status/313430365601669120">
			<p>
				Conditional prob. (a.k.a Bayes' rule), bias/variance trade off, overfitting, x-validation, exploratory vs. confirmatory analysis.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/suzannTee">@suzannTee</a>:
		</p>
		<blockquote cite="http://twitter.com/suzannTee/status/313431125131403264">
			<p>
				the main types of learning algs, the intuition behind them, and the strengths and limitations of each in the context of REAL data.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/marcua">@marcua</a>:
		</p>
		<blockquote cite="http://twitter.com/marcua/status/313431965963522048">
			<p>
				when you can sample, and when you can't
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/StrictlyStat">@StrictlyStat</a>:
		</p>
		<blockquote cite="http://twitter.com/StrictlyStat/status/313432093592014848">
			<p>
				Understanding that the "data" may still transformations to make it a useful covariate - such as scaling per-unit/person measures.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/jmichaethompson">@jmichaethompson</a>:
		</p>
		<blockquote cite="http://twitter.com/jmichaethompson/status/313441915716636673">
			<p>
				Methods that trade-off accuracy for computational resources. That is a gateway drug to being a professional data nerd.
			</p>
		</blockquote>
		<blockquote cite="http://twitter.com/jmichaethompson/status/313444149254844417">
			<p>
				Also: Intuitive description of problem triage into classification, regression and forecasting.
			</p>
		</blockquote>
		<blockquote cite="http://twitter.com/jmichaethompson/status/313444722226130944">
			<p>
				Last thing: how summary statistics can lie to you if you don't look at your data:
				<a href="http://en.wikipedia.org/wiki/Anscombe%27s_quartet">http://en.wikipedia.org/wiki/Anscombe%27s_quartet</a>
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/statalgo">@statalgo</a>:
		</p>
		<blockquote cite="http://twitter.com/statalgo/status/313478753860845568">
			<p>
				I would stick to basics: what is a model (use pictures), linear regression/classification (only supervised), bias/variance tradeoff.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/j4cob">@j4cob</a>:
		</p>
		<blockquote cite="http://twitter.com/j4cob/status/313491917268733952">
			<p>
				confidence intervals.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/jrauser">@jrauser</a>:
		</p>
		<blockquote cite="http://twitter.com/jrauser/status/313528245159071744">
			<p>
				All quantities of interest have uncertainty/error. (Repeated) measuring reduces error. Error drops with the square root of N.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/snoble">@snoble</a>:
		</p>
		<blockquote cite="http://twitter.com/snoble/status/313543249128214528">
			<p>
				if they build their applications to not destroy or modify data they will have useful data when they are ready for data science
			</p>
		</blockquote>
		<blockquote cite="http://twitter.com/snoble/status/313544189235310592">
			<p>
				and the "code ages like fish, data like wine" adage is pretty good. SW engs need to not be too clever in how they capture data.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/ncoghlan_dev">@ncoghlan_dev</a>:
		</p>
		<blockquote cite="http://twitter.com/ncoghlan_dev/status/313559235948589056">
			<p>
				That data exploration and production applications use different priorities to govern the code creation process.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/fhuszar">@fhuszar</a>:
		</p>
		<blockquote cite="http://twitter.com/fhuszar/status/313580151160061952">
			<p>
				That there is difference between training and prediction: training doesn't always have to use billions of data. Also: X-validation.
			</p>
		</blockquote>
		<blockquote cite="http://twitter.com/fhuszar/status/313677744309415937">
			<p>
				Oh, and the fact that counting ~= machine learning.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/dorkitude">@dorkitude</a>:
		</p>
		<blockquote cite="http://twitter.com/dorkitude/status/313668300448079872">
			<p>
				they should know that it's more approachable than they are imagining it is
			</p>
		</blockquote>
		<blockquote cite="http://twitter.com/dorkitude/status/313668714954379265">
			<p>
				emergent vs. prescribed predictive models; described vs. prescribed schema'd; the power of denormalization
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/emilsit">@emilsit</a>:
		</p>
		<blockquote cite="http://twitter.com/emilsit/status/313829472430338050">
			<p>
				I’m not a data person really, but statistics and visualization techniques come to mind.
			</p>
		</blockquote>
		<p>
			From <a href="http://twitter.com/neilkod/status/313998531977428992">@neilkod</a>:
		</p>
		<blockquote cite="http://twitter.com/neilkod/status/313998531977428992">
			<p>
				awk. Tons of code unnecessarily written every day because awk wasn't in someone's tool belt. I've seen it too many times
			</p>
		</blockquote>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-25T06:57:15-07:00">March 25, 2013</time>
			</div>
			<h1><a href="post/2013/03/25/data_science_not_bi/">Data Science And Business Intelligence Not The Same Thing</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



			<p>
				Perhaps I am misunderstand the authors intend, but
				there is <a href="http://blogs.nature.com/naturejobs/2013/03/18/so-you-want-to-be-a-data-scientist">a blog post</a>
				on the <a href="http://blogs.nature.com/naturejobs/">Nature Jobs blog</a> that seems to be conflating
				<em>data science</em> with <em>business intelligence</em>.
				Here is an excerpt from the article:
			</p>
			<blockquote cite="http://blogs.nature.com/naturejobs/2013/03/18/so-you-want-to-be-a-data-scientist">
				<p>
					While programming and statistical expertise is the foundation for any data scientist, a strong background in business and strategy can help jettison a younger scientist's career to the next level.
				</p>
			</blockquote>
			<p>
				The article makes it sound like all <em>data scientists</em> do is <em>business intelligence</em>.
				That is false.
			</p>
			<p>
				Take fellow <a href="http:/datascholars.com">DataScholars</a> blogger and data scientist <a href="http://metadatascience.com/">Massoud Seifi</a> (a.k.a <a href="http://twitter.com/accesstoken">@accesstoken</a>).
				He spends his day as a <em>data scientist</em> dealing with questions on (online) identity and fraud detection &amp; prevention.
			</p>
			<p>
				As another example, I am aware of data science positions where the work is focused on computer vision problems.
				(Again, this has nothing to do with <em>business intelligence</em>.)
			</p>
			<p>
				Although I'm sure there are a number of <em>data scientists</em> who use their skills for <em>business intelligence</em>,
				many <em>data scientists</em> apply their <em>data science</em> skills towards problems that have absolutely nothing to do with <em>business intelligence</em>.
			</p>
			<p>
				For an analogy, it is like someone who has only ever seen software engineers working on iPhone apps; and then declares that all software engineers are iPhone developers.
				Obviously not true.
			</p>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-22T07:29:59-0700">March 22, 2013</time>
			</div>
			<h1><a href="post/2013/03/22/http_graph_gephi/">Visualize And Analyze The Web As You Browse</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="https://marketplace.gephi.org/plugin/http-graph/">HTTP Graph</a> is a <a href="http://gephi.org/">Gephi</a> plugin that lets you visualize and analyze the Web as you browse the web.
		</p>
		<p>
			<a href="http://vimeo.com/18591468">See it in action</a> in the following video.
		</p>
		<figure>
			<iframe src="http://player.vimeo.com/video/18591468" width="500" height="281" frameborder="0" webkitAllowFullScreen="1" mozallowfullscreen="1" allowFullScreen="1"></iframe>
			<figcaption>
				<strong>Figure 1.</strong>
				HTTP Graph - A Gephi plugin
			</figcaption>
		</figure>
	



			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-21T07:21:45-0700">March 21, 2013</time>
			</div>
			<h1><a href="post/2013/03/21/open_data_government_of_canada/">We Love Open Data: Open Data from Government of Canada</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			The "currency" of a <em>data scientist</em>'s vocation is (surprise, surprise) <em>data</em>.
			Sometimes data scientists have to go to great lengths to gather the data sets themselves.
			And sometimes people will "give" it to them. 
		</p>
		<p>
			The government of Canada has done just that.
		</p>
		<p>
			Meet the <a href="http://www.data.gc.ca/">Government of Canada Open Data portal</a>.
		</p>
		<p>
			Explore the data sets they offer yourself.
		</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-20T07:30:51-0700">March 20, 2013</time>
			</div>
			<h1><a href="post/2013/03/20/data_journalism_handbook/">Data Journalism Handbook</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			There are a lot of places where <em>data science</em> can be applied.
			Journalism is one of them.
		</p>
		<p>
			There is a free <a href="http://datajournalismhandbook.org/1.0/en/index.html">book</a> available online that encourages journalists to either start engaging in some limited <em>data science</em> techniques themselves or "connect" with people who can do it for them.
		</p>
		<p>
			The book is called the <a href="http://datajournalismhandbook.org/1.0/en/index.html">Data Journalism Handbook</a>.
			It is a quick read and can give you a bit of insight into how <em>data science</em> can get applied to <em>journalism</em>.
		</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-19T07:52:45-07:00">March 19, 2013</time>
			</div>
			<h1><a href="post/2013/03/19/going_viral_visualization/">Visualizing How Things Go Viral?</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



		<p>
			<a href="http://jakehofman.com/">Jake Hofman</a> talks a bit about <a href="http://www.youtube.com/watch?v=wSwOszoHuoI">visualizing how things go viral</a>.
		</p>
		<figure>
			<iframe width="560" height="315" src="http://www.youtube.com/embed/wSwOszoHuoI" frameborder="0" allowfullscreen="1"></iframe>
			<figcaption>
				<strong>Figure 1.</strong>
				ViralSearch
			</figcaption>
		</figure>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-18T07:21:44-07:00">March 18, 2013</time>
			</div>
			<h1><a href="post/2013/03/18/inferring_fb_creation_date_from_uid_data/">Lookup Table for Inferring Facebook Account Creation Date From Facebook User ID</a></h1>
			<address
				 
					class="reblogged"
				 
			>
				 
					<a rel="bookmark canonical" href="http://metadatascience.com/2013/03/14/lookup-table-for-inferring-facebook-account-creation-date-from-facebook-user-id/">cross-blogged</a>
				 
				by <a href="http://twitter.com/accesstoken">accesstoken</a>
			</address>
			<div>



		<p>
			In my <a href="http://metadatascience.com/2013/03/11/inferring-facebook-account-creation-date-from-facebook-user-id/">previous post</a>, I explained how we can estimate the account creation date of Facebook accounts that have a 15 digit UID without having to call the Facebook API and just based on the user’s Facebook UID.
		</p>
		<p>
			Table below shows the correlation between Facebook UID and Facebook Account Creation Date for the sample set that I analysed.
			The table is represented in <a href="http://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> format as follows:
		</p>
		<p>
			<em>Facebook UID, Account Creation Date(timestamp), Account Creation Date(date)</em>.
		</p>
		<p>
			<strong>Note #1:</strong> To respect the users privacy I hided the last 5 digits of UIDs.
				You may replace ‘x’ by ‘0’ and it should not cause any problem.
		</p>
		<p>
			<strong>Note #2:</strong> For a more accurate result, this table should get updated.
		</p>
		<figure>
<pre><code>
1000053132xxxxx,1361330314,2013-02-19
1000049732xxxxx,1357606484,2013-01-07
1000047422xxxxx,1354021840,2012-11-27
1000047355xxxxx,1353417806,2012-11-20
1000046843xxxxx,1352662415,2012-11-11
1000046015xxxxx,1350999158,2012-10-23
1000035523xxxxx,1349467776,2012-10-05
1000040785xxxxx,1343717040,2012-07-30
1000041143xxxxx,1342928040,2012-07-21
1000038945xxxxx,1338526722,2012-05-31
1000036032xxxxx,1331873652,2012-03-15
1000031133xxxxx,1320583505,2011-11-06
1000031024xxxxx,1320464096,2011-11-04
1000029834xxxxx,1318571069,2011-10-13
1000029345xxxxx,1315974235,2011-09-13
1000026042xxxxx,1309652553,2011-07-02
1000023280xxxxx,1306728328,2011-05-29
1000024582xxxxx,1304995827,2011-05-09
1000023732xxxxx,1303537065,2011-04-22
1000022413xxxxx,1302326877,2011-04-08
1000022328xxxxx,1300810582,2011-03-22
1000019352xxxxx,1295628516,2011-01-21
1000014241xxxxx,1285972221,2010-10-01
1000013861xxxxx,1281882953,2010-08-15
1000014436xxxxx,1280116994,2010-07-25
1000012117xxxxx,1276055448,2010-06-08
1000010697xxxxx,1274090432,2010-05-17
1000010425xxxxx,1272438522,2010-04-28
1000008600xxxxx,1268201411,2010-03-09
1000008113xxxxx,1267667333,2010-03-03
1000006286xxxxx,1266618961,2010-02-19
1000006189xxxxx,1263726284,2010-01-17
1000006449xxxxx,1262406605,2010-01-01
1000003298xxxxx,1261112448,2009-12-17
1000005651xxxxx,1259793952,2009-12-02
1000005426xxxxx,1259605238,2009-11-30
1000005072xxxxx,1258400669,2009-11-16
1000004668xxxxx,1257502719,2009-11-06
1000002286xxxxx,1252567838,2009-09-10
1000001160xxxxx,1250562107,2009-08-17
1000001568xxxxx,1250382196,2009-08-15
</code></pre>
			<figcaption>
				<strong>Figure 1.</strong>
				Correlation between Facebook UID and Facebook Account Creation Date.
				(<a rel="enclosure" href="data/post/2013/03/18/inferring_fb_creation_date_from_uid_data/fbid_accountage.csv">download</a>)
			</figcaption>
		</figure>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-17T15:21:14-07:00">March 17, 2013</time>
			</div>
			<h1><a href="post/2013/03/17/forensic_analysis_of_phone_call_networks/">Forensic Analysis of Phone Call Networks (Salvatore Catanese, Emilio Ferrara, Giacomo Fiumara)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



			<blockquote cite="http://arxiv.org/abs/cs/0703109">
				<p>
					In the context of preventing and fighting crime, the analysis of mobile phone traffic, among actors of a criminal network, is helpful in order to reconstruct illegal activities on the base of the relationships connecting those specific individuals. Thus, forensic analysts and investigators require new advanced tools and techniques which allow them to manage these data in a meaningful and efficient way. In this paper we present LogAnalysis, a tool we developed to provide visual data representation and filtering, statistical analysis features and the possibility of a temporal analysis of mobile phone activities. Its adoption may help in unveiling the structure of a criminal network and the roles and dynamics of communications among its components. By using LogAnalysis, forensic investigators could deeply understand hierarchies within criminal organizations, for example discovering central members that provide connections among different sub-groups, etc. Moreover, by analyzing the temporal evolution of the contacts among individuals, or by focusing on specific time windows they could acquire additional insights on the data they are analyzing. Finally, we put into evidence how the adoption of LogAnalysis may be crucial to solve real cases, providing as example a number of case studies inspired by real forensic investigations led by one of the authors.
				</p>
			</blockquote>
			<p>
				<a href="http://arxiv.org/abs/1303.1827">arXiv:1303.1827</a> [cs.SI]
			</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-15T07:38:12-07:00">March 15, 2013</time>
			</div>
			<h1><a href="post/2013/03/15/inferring_fb_creation_date_from_uid/">Inferring Facebook Account Creation Date From Facebook User ID</a></h1>
			<address
				 
					class="reblogged"
				 
			>
				 
					<a rel="bookmark canonical" href="http://metadatascience.com/2013/03/11/inferring-facebook-account-creation-date-from-facebook-user-id/">cross-blogged</a>
				 
				by <a href="http://twitter.com/accesstoken">accesstoken</a>
			</address>
			<div>



		<p>
			Calling the Facebook API is a (relatively) slow operation; especially if you have to call it multiple times.
			So, when possible, it is a good idea to get the information you need, without making API calls.
		</p>
		<p>
			Here I show you how to figure out the <em>creation date</em> of a Facebook account without having to call the Facebook API, just based on the user’s Facebook UID.
		</p>

		<h2>The Bad Way To Do It</h2>
		<p>
			As I explained in <a href="http://metadatascience.com/2013/03/05/how-to-estimate-the-facebook-account-creation-date/">my previous post</a>,
			it is possible to estimate the Facebook account creation date by retrieving the date of user’s oldest post.
			This method has a couple of draw backs:
		</p>
		<p>
			<strong>Draw Back #1</strong>:
			<img src="data/post/2013/03/15/inferring_fb_creation_date_from_uid/screenshot_read_stream.png" width="356" align="right" height="262" title="read_stream"/>
			You must have <em>‘read_stream’</em> permission which is an extended Facebook permission to read the user post stream.
			From a user’s point of view, this sounds scarier than the other basic permissions you probably ask for.
		</p>
		<p>
			<strong>Draw Back #2</strong>: As an extended permission it triggers a second permission screen that dramatically increases the <a href="http://en.wikipedia.org/wiki/User_experience">UX</a> friction for the users.
			(You want <em>low</em> friction UX.)
		</p>
		<p>
			<strong>Draw Back #3</strong>: The overhead of walking the entire post stream to determine age is very costly for the simple piece of information we synthesize.
			(You have to call the Facebook API over and over and over and over … again, since the post stream is paginated.
			I.e., this is at best an O(n) operation, where “n” relates to the user’s activity on Facebook.)
		</p>

		<h2>My Search For A Better Way</h2>
		<p>
			To overcome these issues I tried an to find an alternative, asynchronous approach.
			I was wondering if it is possible to estimate a Facebook account creation date by looking at Facebook User ID.
			I couldn’t find any official documentation on how Facebook generates a new Facebook user ID and how they are accomplishing that in a scalable fashion.
			One answer I could find was from <em>Jack Lindamood, Software Engineer at Facebook 2008-2012</em> which I found <a href="http://www.quora.com/Facebook-1/How-do-Facebook-use-incremented-IDs-for-both-users-and-Pages">here</a>:
		</p>
		<blockquote>
			<p>
				‘Lots’ of MySQL DBs.
				Each with their own unique number.
				Also, each has an autoincrement table.
				Then it’s just some math on the autoincrement value + unique_number * some_cap_per_db (it’s a bit more complicated due to special cases, but that’s pretty much how it works).
			</p>
		</blockquote>
		<p>
			Another explanation was from <em>Justin Mitchell, former engineering manager</em>.
			He explains <a href="http://www.quora.com/Facebook-Company-History/What-is-the-history-of-Facebooks-user-ID-numbering-system">here</a> the history of Facebook user ID numbering system:
		</p>
		<blockquote>
			<p>
				Facebook’s user ID schema reflects the history of the site as it transitioned from a single-server single-school operation to 400 million users. 
				User ID assignment has gone through several phases, notably:
			</p>
			<p>
				Harvard only.
				Facebook (or thefacebook.com, as it was called back then) was opened up to Harvard running off a single box that had mysql and apache.
				IDs were auto-incremented, starting at 4 (hi Zuck).
			</p>
			<p>
				Other schools.
				Other schools were initially completely separate sites, operating on their own boxes.
				IDs were still auto-increment per SQL box, but each server/school had a different prefix.
				For instance, all Columbia IDs are between 100000-199999 and all Stanford IDs are between 200000-299999.
				You can determine what school any early Facebook user attended based on his or her user ID.
			</p>
			<p>
				High schools.
				Someone must have figured out that this ID system didn’t scale very well, so Facebook changed its DB layout when high schools were introduced.
				While all the college users maintained their current DB, high school users were randomly assigned to one of many many high school DBs.
				These users IDs hash to the correct database, rather than simply being floor(ID / 100000).
			</p>
			<p>
				Open registration.
				Facebook maintained a similar layout once open reg was launched, except the new databases weren’t signified as “high school.”
			</p>
			<p>
				64 bit.
				Given Facebook’s growth rate, it was estimated that the entire world would be on the site by 2011, overflowing 32-bit space.
				While we considered limiting the site to the first 4-billion people to register and lobbying governments to reduce the world’s population, the growth team pushed pretty hard to just increase the ID space to 64-bit.
			</p>
		</blockquote>

		<h2>Using Facecbook UIDs For Predictions</h2>
		<p>
			So it seems that new Facebook IDs are 64 bits and contain 15 digits.
			There is a <a href="https://developers.facebook.com/blog/post/45/">post</a> dating from October 2007 that mentions that Facebook had plans to do this long time ago but according to this <a href="https://developers.facebook.com/blog/post/226/">post</a> from May, 2009, Facebook was going to release 64 bit user IDs back to 2009.
		</p>
		<p>
			I studied the correlation between Facebook User ID and Account Creation Date for a <em>tiny sample set</em> of 77 Facebook accounts.
			41 accounts of this sample set had a user ID containing 15 digits and for the rest the user ID has less than 15 digits.
			Figures below illustrate this correlation seperately for 64 bit UIDS (<em>figure 1</em>) and old style UIDs (<em>figure 2</em>).
		</p>
		<figure>
			<img src="data/post/2013/03/15/inferring_fb_creation_date_from_uid/fbid_age_15.png" width="390" height="390" title="uid==15"/>
			<figcaption>
				<strong>Figure 1.</strong>
			</figcaption>
		</figure>
		<figure>
			<img src="data/post/2013/03/15/inferring_fb_creation_date_from_uid/fbid_age_less.png" width="390" height="390" title="uid&lt;15"/>
			<figcaption>
				<strong>Figure 2.</strong>
			</figcaption>
		</figure>
		<p>
			The graph in <em>figure 1</em> is for the new(er) Facebook UIDs.
			The graph in <em>figure 2</em> is for the old style Facebook IDs.
			You can see that the correlation between Facebook UID and its <em>creation date</em> is <strong>a lot</strong> better for the new(er) Facebook UIDs than the old ones.
		</p>
		<p>
			Or in other words, as we observe, there is an interesting correlation between Facebook User ID and Account Creation Date for 64 bit user IDs (see <em>figure 1</em>).
			Also in this sample set, old UIDs are more than 800 days old (see <em>figure 2</em>).
			The overlap between two graphs might be a period that Facebook was moving from old UIDs to 64 bit ones.
		</p>
		<p>
			<strong>Therefore as an alternative approach to estimate the Facebook account creation date, we may leverage the monotonically increasing property of 64 bit Facebook user IDs and create a table of bounds that would give us at least a quarterly estimate on the creation date for the account - an appropriate level of granularity for this purpose.</strong>
			Taking this approach will reduce the number of permissions your application need and dramatically decrease the amount of processing time and remove a variable around the elapsed time to deliver a response.
		</p>
		<p>
			<span style="color:red"><b>Update (March 14, 2013):</b></span> 
			See <a href="http://metadatascience.com/2013/03/14/lookup-table-for-inferring-facebook-account-creation-date-from-facebook-user-id/">here</a> to download the data set.
		</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-14T06:44:41-07:00">March 14, 2013</time>
			</div>
			<h1><a href="post/2013/03/14/tag-cloud_drawing/">Tag-Cloud Drawing: Algorithms for Cloud Visualization (Owen Kaser, Daniel Lemire)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



			<blockquote cite="http://arxiv.org/abs/cs/0703109">
				<p>
					Tag clouds provide an aggregate of tag-usage statistics. They are typically sent as in-line HTML to browsers. However, display mechanisms suited for ordinary text are not ideal for tags, because font sizes may vary widely on a line. As well, the typical layout does not account for relationships that may be known between tags. This paper presents models and algorithms to improve the display of tag clouds that consist of in-line HTML, as well as algorithms that use nested tables to achieve a more general 2-dimensional layout in which tag relationships are considered. The first algorithms leverage prior work in typesetting and rectangle packing, whereas the second group of algorithms leverage prior work in Electronic Design Automation. Experiments show our algorithms can be efficiently implemented and perform well.
				</p>
			</blockquote>
			<p>
				<a href="http://arxiv.org/abs/cs/0703109">arXiv:cs/0703109</a> [cs.DS]
			</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-13T06:47:52-07:00">March 13, 2013</time>
			</div>
			<h1><a href="post/2013/03/13/fb_creation_date_estimate/">How to Estimate the Facebook Account Creation Date</a></h1>
			<address
				 
					class="reblogged"
				 
			>
				 
					<a rel="bookmark canonical" href="http://metadatascience.com/2013/03/05/how-to-estimate-the-facebook-account-creation-date/">cross-blogged</a>
				 
				by <a href="http://twitter.com/accesstoken">accesstoken</a>
			</address>
			<div>



		<p>
			Facebook <a href="http://developers.facebook.com/docs/reference/api/">Graph API</a> and <a href="http://developers.facebook.com/docs/reference/fql/">FQL</a> don’t provide you with a simple way of getting the creation date of a Facebook account.
			But if you have a valid Facebook <a href="http://developers.facebook.com/tools/explorer">Access Token</a> with <em>‘read_stream’</em> permission, it is possible to estimate the Facebook account creation date by finding the creation date of the oldest user post.
			According to the Facebook documentation,
		</p>
		<blockquote>
			<p>
				each query of the stream table is limited to the previous 30 days or 50 posts, whichever is greater, however you can use time-specific fields such as created_time along with FQL operators (such as &lt; or &gt;) to retrieve a much greater range of posts.
			</p>
		</blockquote>
		<p>
			Also you must have <em>‘read_stream’</em> permission:
		</p>
		<blockquote>
			<p>
				Querying without the <em>‘read_stream’</em> permission will return only the public view of the data (i.e. data that can be see when the user is logged out).
			</p>
		</blockquote>
		<p>
			Here is some code to do that:
		</p>
		<figure>
<pre><code>
/**
 * Estimating the Facebook account age by finding the creation date of the oldest post.
 * A valid Facebook Access Token with read_stream permission is required.
 *
 * @author Massoud Seifi, Ph.D. @ MetaDataScience.com
 */

class AccountAge
{

	public $baseUrl;

	function __construct()
	{
		$this-&gt;baseUrl = 'https://graph.facebook.com/';
	}

	/**
	 * Run a Facebook FQL query
	 * @param string $fql Facebook query 
	 * @param string $access_token Facebook Access Token
	 * @return array Return Facebook query result
	 */
	public function doFQLRequest($fql, $access_token)
	{
		$url = $this-&gt;baseUrl	. 'fql?q=' . urlencode($fql)
			. '&amp;access_token=' . $access_token;
		$ch = curl_init($url);
		curl_setopt($ch, CURLOPT_TIMEOUT, 60);
		curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
		curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);

		$decodedResult = json_decode(curl_exec($ch), true);
		curl_close($ch);

		$result = array();
		if(isset($decodedResult['data']))
			$result = $decodedResult['data'];
		else
			throw new Exception("Facebook FQL Error. Please check if the access token is valid.\n");

		return $result;
	}

	/**
	 * Estimate the account age by finding the creation date of the oldest post
	 * @param string $access_token Facebook Access Token
	 * @return integer Return the Facebook account age in seconds
	 */
	public function getAccountAge($access_token)
	{
		$date = new \DateTime('now');
		$timestamp = $date-&gt;getTimestamp();
		echo "# Finding the oldest post may take several minutes to complete.\n";
		echo "# Please wait ";
		while (true){ // Loop until finding the oldest post
			echo ".";
			$fql = "SELECT created_time FROM stream WHERE source_id = me()"
				. " AND created_time &lt; " . $timestamp
				. " ORDER BY created_time ASC LIMIT 5000";
			$result = $this-&gt;doFQLRequest($fql, $access_token);
			if (!isset($result[0]['created_time']))
				break;
			$timestamp = $result[0]['created_time'];
		}
		echo "\n";
		$age = $date-&gt;getTimestamp() - $timestamp;
		return $age;
	}


	/**
	 * Display the account age in a human readable format
	 * @param int $age Account age in seconds
	 */
	public function printAccountAge($age)
	{
		$years = floor($age / (365*24*60*60));
		$months = floor(($age - $years * 365*24*60*60) / (30*24*60*60));
		$days = floor(($age - $years * 365*24*60*60 - $months * 30*24*60*60) / (24*60*60));
		echo "\nAccount age: $years years, $months months, $days days\n";	
	}

}

$p = new AccountAge();
// You need an Access Token with a read_stream permission
$access_token = 'AAACEdEose0cBAOY7bB3A9m7s3U6hbuJvfECxuZBFRN6YjqPC2eZB5x8WrnK51Gl3WsdwYovmxdPZCKFyJKB5TuFhpxsDJpAZCe9y6eutyQZDZD';
$age = $p-&gt;getAccountAge($access_token);
$p-&gt;printAccountAge($age);
</code></pre>
		</figure>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-12T07:14:33-07:00">March 12, 2013</time>
			</div>
			<h1><a href="post/2013/03/12/facebook_likes_as_a_predictor/">Private traits and attributes are predictable from digital records of human behavior (Michal Kosinskia, David Stillwell, and Thore Graepel)</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



			<blockquote cite="http://arxiv.org/abs/cs/0703109">
				<p>
					We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88% of cases, African Americans and Caucasian Americans in 95% of cases, and between Democrat and Republican in 85% of cases. For the personality trait “Openness,” prediction accuracy is close to the test–retest accuracy of a standard personality test. We give examples of associations between attributes and Likes and discuss implications for online personalization and privacy.
				</p>
			</blockquote>
			<p>
				<a href="http://www.pnas.org/content/early/2013/03/06/1218772110.abstract">PNAS 2013 : 1218772110v1-201218772</a>
			</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>







		<article>
			<div class="pubdate">
				<time datetime="2013-03-11T07:32:53-07:00">March 11, 2013</time>
			</div>
			<h1><a href="post/2013/03/11/data_science_meetup_vancouver/">New Data Science Meetup Group In Vancouver</a></h1>
			<address
				 
			>
				 
				by <a href="http://twitter.com/reiver">reiver</a>
			</address>
			<div>



			<p>
					There is a new <a href="http://www.meetup.com/DataScience/">data science meetup group in Vancouver</a>.
					If you are in Vancouver and are into <em>data science</em>, then you should <a href="http://www.meetup.com/DataScience/">join this</a>.
			</p>
	



			</div>
			<div class="comments">
				no comments
			</div>
		</article>



		<div class="pagination">
			<nav>
				<ul>
					<li>
						<a href="page/by10/shift0/0.html">Older Page &#8827;</a>
					</li>
				</ul>
			<nav>
		</div>

		<footer>
			<a href="http://twitter.com/DataScholars"><img src="i/twitter.png" alit="twitter"></a>
		</footer>


		<script src="3/jquery/jquery-1.9.1.min.js"></script>
		<script src="3/typeset/src/linked-list.js"></script>
		<script src="3/typeset/src/linebreak.js"></script>
		<script src="3/typeset/lib/hypher.js"></script>
		<script src="3/typeset/lib/en-us.js"></script>

		<script src="3/d3/d3.v3.min.js"></script>
		<script src="3/jsnetworkx/jsnetworkx.js"></script>

		<script src="webstats.js"></script>
	</body>
</html>
